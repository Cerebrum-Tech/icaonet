{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5448ff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('..')\n",
    "path.append('../../src/')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, basename\n",
    "from glob import glob\n",
    "\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE, FOLDER_IMAGES, FOLDER_MRKS\n",
    "from local_config import FOLDER_MODELS, FILE_DATASET\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from custom_metrics import eye_localization_fvc, eye_localization_accuracy\n",
    "from icao_dataset import ICAODataset\n",
    "from utils import plot, load\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287425ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/unsupervised_supervised/\n",
      "../../data/cropped_faces_eyes/dataset_dlib.pkl\n",
      "../../models/unsupervised_supervised/model_2022_07_13-21_29_34.h5\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ROOT = '../../'\n",
    "\n",
    "FOLDER_MODELS = join(PATH_TO_ROOT, FOLDER_MODELS)\n",
    "FILE_DATASET = join(PATH_TO_ROOT, FILE_DATASET)\n",
    "FILE_MODEL = join(FOLDER_MODELS, 'model_2022_07_13-21_29_34.h5')\n",
    "\n",
    "print(FOLDER_MODELS)\n",
    "print(FILE_DATASET)\n",
    "print(FILE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea362c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640afc32",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2f4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pkl.load(open(FILE_DATASET, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6e2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 160, 160, 3) float32\n",
      "(5574, 23) int32\n",
      "(5574, 4) float64\n",
      "5574\n"
     ]
    }
   ],
   "source": [
    "x = np.array(dataset.images)\n",
    "mrks = np.array(dataset.mrks)\n",
    "y_reqs = np.array([mrk_file.photo_reqs.values() for mrk_file in mrks])\n",
    "y_eyes = np.array([mrk_file.right_eye.center().as_list() + mrk_file.left_eye.center().as_list() for mrk_file in mrks])\n",
    "\n",
    "print(x.shape, x.dtype)\n",
    "print(y_reqs.shape, y_reqs.dtype)\n",
    "print(y_eyes.shape, y_eyes.dtype)\n",
    "print(len(mrks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d2d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= 255\n",
    "y_eyes /= x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a60673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565, 160, 160, 3) (565, 23) (565, 4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "_, _, x_val_idx, y_val_reqs = iterative_train_test_split(\n",
    "    np.arange(x.shape[0]).reshape(-1, 1),\n",
    "    y_reqs,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "x_val_idx = x_val_idx.ravel()\n",
    "x_val = x[x_val_idx]\n",
    "y_val_eyes = y_eyes[x_val_idx]\n",
    "\n",
    "print(x_val.shape, y_val_reqs.shape, y_val_eyes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e0321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "../../data/cropped_faces/images/afwDB_0.png\n",
      "1 of 1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reqs:\n",
      "0.64809215\n",
      "0.9347415\n",
      "0.99573874\n",
      "0.08281669\n",
      "0.991169\n",
      "0.9998725\n",
      "0.9772672\n",
      "0.27883732\n",
      "0.96358013\n",
      "0.053408027\n",
      "0.20580012\n",
      "0.14253017\n",
      "0.9828384\n",
      "0.47127613\n",
      "0.8292506\n",
      "0.99030715\n",
      "0.7546116\n",
      "0.97962976\n",
      "0.89305204\n",
      "0.65849125\n",
      "0.9751568\n",
      "0.82795393\n",
      "0.9905076\n",
      "\n",
      "Eyes:\n",
      "0.42364126\n",
      "0.44919902\n",
      "0.578478\n",
      "0.44857737\n"
     ]
    }
   ],
   "source": [
    "model = load_model(FILE_MODEL)\n",
    "\n",
    "list_files = [PATH_TO_ROOT + 'data/cropped_faces/images/afwDB_0.png']\n",
    "random_file = np.random.choice(list_files)\n",
    "print(random_file)\n",
    "\n",
    "im = load.images_from_list_files([random_file], output_size=IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "im /= 255\n",
    "\n",
    "y_pred_clf, y_pred_reg = model.predict(im)\n",
    "\n",
    "print(\"Reqs:\")\n",
    "for y_pred in y_pred_clf[0]:\n",
    "    print(y_pred)\n",
    "\n",
    "print(\"\\nEyes:\")\n",
    "for y_pred in y_pred_reg[0]:\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdaf6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_pred_eyes = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c66e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39469026548672564\n",
      "0.4725663716814159\n",
      "0.10088495575221239\n",
      "0.03185840707964602\n"
     ]
    }
   ],
   "source": [
    "d_eye_1 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, max_threshold=0.1)\n",
    "d_eye_1_2 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.1, max_threshold=0.2)\n",
    "d_eye_2_3 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.2, max_threshold=0.3)\n",
    "d_eye_3 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.3)\n",
    "\n",
    "print(d_eye_1.eval(session=sess))\n",
    "print(d_eye_1_2.eval(session=sess))\n",
    "print(d_eye_2_3.eval(session=sess))\n",
    "print(d_eye_3.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6c77e",
   "metadata": {},
   "source": [
    "#  Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70465cc1",
   "metadata": {},
   "source": [
    "### Images with worst `d_eyes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba68b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = \"error_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421c19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01748566682929265 0.4645883515093726\n"
     ]
    }
   ],
   "source": [
    "d_eyes = eye_localization_fvc(y_val_eyes, y_pred_eyes).eval(session=sess)\n",
    "print(d_eyes.min(), d_eyes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c504a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_eyes_argsort = np.argsort(d_eyes)\n",
    "\n",
    "worst_indices = d_eyes_argsort[-30:]\n",
    "filenames = np.array(dataset.image_files)[x_val_idx]\n",
    "\n",
    "for index in worst_indices:\n",
    "    im = (x_val[index] * 255).astype(np.uint8)\n",
    "    y_true = y_val_eyes[index] * IMAGE_SIZE[0]\n",
    "    y_pred = y_pred_eyes[index] * IMAGE_SIZE[0]\n",
    "    d_eye = d_eyes[index]\n",
    "    \n",
    "    true_r = tuple(y_true[:2].astype(np.int))\n",
    "    true_l = tuple(y_true[2:].astype(np.int))\n",
    "    pred_r = tuple(y_pred[:2].astype(np.int))\n",
    "    pred_l = tuple(y_pred[2:].astype(np.int))\n",
    "    cv2.circle(im, true_r, radius=0, color=(0, 255, 0))\n",
    "    cv2.circle(im, true_l, radius=0, color=(0, 255, 0))\n",
    "    cv2.circle(im, pred_r, radius=0, color=(255, 255, 0))\n",
    "    cv2.circle(im, pred_l, radius=0, color=(255, 255, 0))\n",
    "    \n",
    "    cv2.imwrite(join(FOLDER_OUTPUT, f\"{np.round(d_eye, 3):.3f}.png\"), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb78c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
