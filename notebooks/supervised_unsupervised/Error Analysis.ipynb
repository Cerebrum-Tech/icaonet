{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5448ff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('..')\n",
    "path.append('../../src/')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, basename\n",
    "from glob import glob\n",
    "\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE, FOLDER_IMAGES, FOLDER_MRKS\n",
    "from local_config import FOLDER_MODELS, FILE_DATASET\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from custom_metrics import eye_localization_fvc, eye_localization_accuracy\n",
    "from icao_dataset import ICAODataset\n",
    "from utils import plot, load\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287425ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/unsupervised_supervised/\n",
      "../../data/cropped_faces_eyes/dataset_dlib.pkl\n",
      "../../models/unsupervised_supervised/model_2022_07_13-21_29_34.h5\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ROOT = '../../'\n",
    "\n",
    "FOLDER_MODELS = join(PATH_TO_ROOT, FOLDER_MODELS)\n",
    "FILE_DATASET = join(PATH_TO_ROOT, FILE_DATASET)\n",
    "FILE_MODEL = join(FOLDER_MODELS, 'model_2022_07_13-21_29_34.h5')\n",
    "\n",
    "print(FOLDER_MODELS)\n",
    "print(FILE_DATASET)\n",
    "print(FILE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea362c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640afc32",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2f4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pkl.load(open(FILE_DATASET, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6e2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 160, 160, 3) float32\n",
      "(4999, 23) int32\n",
      "(4999, 4) float64\n",
      "4999\n"
     ]
    }
   ],
   "source": [
    "x = np.array(dataset.images)\n",
    "mrks = np.array(dataset.mrks)\n",
    "y_reqs = np.array([mrk_file.photo_reqs.values() for mrk_file in mrks])\n",
    "y_eyes = np.array([mrk_file.right_eye.center().as_list() + mrk_file.left_eye.center().as_list() for mrk_file in mrks])\n",
    "\n",
    "print(x.shape, x.dtype)\n",
    "print(y_reqs.shape, y_reqs.dtype)\n",
    "print(y_eyes.shape, y_eyes.dtype)\n",
    "print(len(mrks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d2d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= 255\n",
    "y_eyes /= x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a60673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509, 160, 160, 3) (509, 23) (509, 4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "_, _, x_val_idx, y_val_reqs = iterative_train_test_split(\n",
    "    np.arange(x.shape[0]).reshape(-1, 1),\n",
    "    y_reqs,\n",
    "    test_size=TEST_SIZE\n",
    ")\n",
    "x_val_idx = x_val_idx.ravel()\n",
    "x_val = x[x_val_idx]\n",
    "y_val_eyes = y_eyes[x_val_idx]\n",
    "\n",
    "print(x_val.shape, y_val_reqs.shape, y_val_eyes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e0321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "../../data/cropped_faces/images/afwDB_0.png\n",
      "1 of 1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reqs:\n",
      "0.6480921\n",
      "0.9347415\n",
      "0.9957387\n",
      "0.08281675\n",
      "0.991169\n",
      "0.9998725\n",
      "0.97726715\n",
      "0.27883765\n",
      "0.96358013\n",
      "0.053408027\n",
      "0.20580027\n",
      "0.14253017\n",
      "0.9828384\n",
      "0.471276\n",
      "0.8292505\n",
      "0.99030715\n",
      "0.7546116\n",
      "0.9796297\n",
      "0.89305204\n",
      "0.6584904\n",
      "0.9751569\n",
      "0.827954\n",
      "0.9905076\n",
      "\n",
      "Eyes:\n",
      "0.42364126\n",
      "0.449199\n",
      "0.578478\n",
      "0.44857737\n"
     ]
    }
   ],
   "source": [
    "model = load_model(FILE_MODEL)\n",
    "\n",
    "list_files = [PATH_TO_ROOT + 'data/cropped_faces/images/afwDB_0.png']\n",
    "random_file = np.random.choice(list_files)\n",
    "print(random_file)\n",
    "\n",
    "im = load.images_from_list_files([random_file], output_size=IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "im /= 255\n",
    "\n",
    "y_pred_clf, y_pred_reg = model.predict(im)\n",
    "\n",
    "print(\"Reqs:\")\n",
    "for y_pred in y_pred_clf[0]:\n",
    "    print(y_pred)\n",
    "\n",
    "print(\"\\nEyes:\")\n",
    "for y_pred in y_pred_reg[0]:\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdaf6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_pred_eyes = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c66e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4263261296660118\n",
      "0.48722986247544203\n",
      "0.07072691552062868\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "d_eye_1 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, max_threshold=0.1)\n",
    "d_eye_1_2 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.1, max_threshold=0.2)\n",
    "d_eye_2_3 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.2, max_threshold=0.3)\n",
    "d_eye_3 = eye_localization_accuracy(y_val_eyes, y_pred_eyes, min_threshold=0.3)\n",
    "\n",
    "print(d_eye_1.eval(session=sess))\n",
    "print(d_eye_1_2.eval(session=sess))\n",
    "print(d_eye_2_3.eval(session=sess))\n",
    "print(d_eye_3.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6c77e",
   "metadata": {},
   "source": [
    "#  Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70465cc1",
   "metadata": {},
   "source": [
    "### Images with worst `d_eyes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba68b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = \"error_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421c19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01748566682929265 0.4645883515093726\n"
     ]
    }
   ],
   "source": [
    "d_eyes = eye_localization_fvc(y_val_eyes, y_pred_eyes).eval(session=sess)\n",
    "print(d_eyes.min(), d_eyes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c504a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_eyes_argsort = np.argsort(d_eyes)\n",
    "\n",
    "worst_indices = d_eyes_argsort[-30:]\n",
    "filenames = np.array(dataset.image_files)[x_val_idx]\n",
    "\n",
    "for index in worst_indices:\n",
    "    im = (x_val[index] * 255).astype(np.uint8)\n",
    "    y_true = y_val_eyes[index] * IMAGE_SIZE[0]\n",
    "    y_pred = y_pred_eyes[index] * IMAGE_SIZE[0]\n",
    "    d_eye = d_eyes[index]\n",
    "    \n",
    "    true_r = tuple(y_true[:2].astype(np.int))\n",
    "    true_l = tuple(y_true[2:].astype(np.int))\n",
    "    pred_r = tuple(y_pred[:2].astype(np.int))\n",
    "    pred_l = tuple(y_pred[2:].astype(np.int))\n",
    "    cv2.circle(im, true_r, radius=0, color=(0, 255, 0))\n",
    "    cv2.circle(im, true_l, radius=0, color=(0, 255, 0))\n",
    "    cv2.circle(im, pred_r, radius=0, color=(255, 255, 0))\n",
    "    cv2.circle(im, pred_l, radius=0, color=(255, 255, 0))\n",
    "    \n",
    "    cv2.imwrite(join(FOLDER_OUTPUT, f\"{np.round(d_eye, 3):.3f}.png\"), im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503bf45",
   "metadata": {},
   "source": [
    "# Heatmap of Eye's predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f8af158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(y_pred):\n",
    "    y_pred = (y_pred * IMAGE_SIZE[0]).astype(np.uint)\n",
    "    im = np.zeros(IMAGE_SIZE)\n",
    "    \n",
    "    for xl, yl, xr, yr in y_pred:\n",
    "        im[yl, xl] += 1\n",
    "        im[yr, xr] += 1\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4eea3702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "FILE_MODEL = FILE_MODEL = join(FOLDER_MODELS, 'model_2022_08_06-11_38_47.h5')\n",
    "\n",
    "model = load_model(FILE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0cf934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42533278, 0.45768124, 0.5762939 , 0.45392954],\n",
       "       [0.42573524, 0.45227724, 0.5744512 , 0.44815603],\n",
       "       [0.42006063, 0.45833614, 0.56966835, 0.45283583],\n",
       "       ...,\n",
       "       [0.42096362, 0.45062664, 0.5702216 , 0.4467097 ],\n",
       "       [0.41828883, 0.4406848 , 0.5740653 , 0.43589523],\n",
       "       [0.42004097, 0.44625118, 0.5771619 , 0.44308105]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, y_pred_eyes = model.predict(x_val)\n",
    "y_pred_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56463364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x159754d3908>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_heatmap = heatmap(y_pred_eyes)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im_heatmap, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc6692e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67.16502947 73.26522593]\n",
      "[92.77013752 72.81335953]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_eyes * IMAGE_SIZE[0]).astype(np.uint)\n",
    "print(y_pred[:, :2].mean(axis=0))\n",
    "print(y_pred[:, 2:].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d546679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_left</th>\n",
       "      <th>n_left</th>\n",
       "      <th>pixel_right</th>\n",
       "      <th>n_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(67, 72)</td>\n",
       "      <td>138</td>\n",
       "      <td>(92, 72)</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(68, 72)</td>\n",
       "      <td>92</td>\n",
       "      <td>(92, 71)</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(66, 78)</td>\n",
       "      <td>69</td>\n",
       "      <td>(96, 78)</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(68, 73)</td>\n",
       "      <td>50</td>\n",
       "      <td>(93, 72)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(67, 73)</td>\n",
       "      <td>35</td>\n",
       "      <td>(91, 72)</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(67, 71)</td>\n",
       "      <td>32</td>\n",
       "      <td>(93, 71)</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(66, 79)</td>\n",
       "      <td>15</td>\n",
       "      <td>(96, 77)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(68, 71)</td>\n",
       "      <td>12</td>\n",
       "      <td>(92, 73)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(68, 74)</td>\n",
       "      <td>12</td>\n",
       "      <td>(91, 71)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(66, 72)</td>\n",
       "      <td>10</td>\n",
       "      <td>(90, 71)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pixel_left  n_left pixel_right  n_right\n",
       "0   (67, 72)     138    (92, 72)      144\n",
       "1   (68, 72)      92    (92, 71)       71\n",
       "2   (66, 78)      69    (96, 78)       64\n",
       "3   (68, 73)      50    (93, 72)       34\n",
       "4   (67, 73)      35    (91, 72)       28\n",
       "5   (67, 71)      32    (93, 71)       19\n",
       "6   (66, 79)      15    (96, 77)       18\n",
       "7   (68, 71)      12    (92, 73)       17\n",
       "8   (68, 74)      12    (91, 71)       16\n",
       "9   (66, 72)      10    (90, 71)       14"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "count_left = defaultdict(int)\n",
    "count_right = defaultdict(int)\n",
    "for xl, yl, xr, yr in y_pred:\n",
    "    count_left[(xl, yl)] += 1\n",
    "    count_right[(xr, yr)] += 1\n",
    "    \n",
    "df_left = pd.DataFrame(Counter(count_left).most_common(n=10), columns=[\"pixel_left\", \"n_left\"])\n",
    "df_right = pd.DataFrame(Counter(count_right).most_common(n=10), columns=[\"pixel_right\", \"n_right\"])\n",
    "pd.concat([df_left, df_right], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e988c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
