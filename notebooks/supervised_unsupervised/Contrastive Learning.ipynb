{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('..')\n",
    "path.append('../../src/')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from os.path import basename, join\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Lambda, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, GlobalAvgPool2D, Layer\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE, FILE_DUMP_IMAGES, FILE_DUMP_MRKS\n",
    "from local_config import FOLDER_MODELS, FILE_AUTOENCODER_SAMPLES\n",
    "from custom_metrics import precision, recall, f1, specificity, fbeta\n",
    "from custom_metrics import negative_predictive_value as npv \n",
    "from custom_metrics import matthews_correlation_coefficient as mcc\n",
    "from utils import plot, load\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ROOT = '../../'\n",
    "\n",
    "FOLDER_LOGS = join(PATH_TO_ROOT, 'logs')\n",
    "FOLDER_MODELS = join(PATH_TO_ROOT, FOLDER_MODELS)\n",
    "FILE_DUMP_MRKS = join(PATH_TO_ROOT, FILE_DUMP_MRKS)\n",
    "FILE_DUMP_IMAGES = join(PATH_TO_ROOT, FILE_DUMP_IMAGES)\n",
    "FILE_AUTOENCODER_SAMPLES = join(PATH_TO_ROOT, FILE_AUTOENCODER_SAMPLES)\n",
    "\n",
    "print(FOLDER_LOGS)\n",
    "print(FOLDER_MODELS)\n",
    "print(FILE_DUMP_MRKS)\n",
    "print(FILE_DUMP_IMAGES)\n",
    "print(FILE_AUTOENCODER_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "MLFLOW_EXPERIMENT_NAME = 'Unsupervised + Supervised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_model_name(prefix='model_', suffix='', format='%Y_%m_%d-%H_%M_%S', ext='.h5'):\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(format)\n",
    "    return f'{prefix}{timestamp}{suffix}{ext}'\n",
    "\n",
    "\n",
    "def set_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    rn.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = pkl.load(open(FILE_DUMP_IMAGES, 'rb'))\n",
    "mrks, _ = pkl.load(open(FILE_DUMP_MRKS, 'rb'))\n",
    "y = np.array([mrk_file.photo_reqs.values() for mrk_file in mrks])\n",
    "\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)\n",
    "print(len(mrks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "x_train_idx, y_train, x_val_idx, y_val = iterative_train_test_split(np.arange(x.shape[0]).reshape(-1, 1), y, test_size=TEST_SIZE)\n",
    "x_train_idx = x_train_idx.ravel()\n",
    "x_val_idx = x_val_idx.ravel()\n",
    "\n",
    "x_train = x[x_train_idx]\n",
    "x_val = x[x_val_idx]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mrks = mrks[x_train_idx]\n",
    "val_mrks = mrks[x_val_idx]\n",
    "\n",
    "# pkl.dump((x_train, x_val, train_mrks, val_mrks), open(FILE_AUTOENCODER_SAMPLES, 'wb'), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, _, _ = pkl.load(open(FILE_AUTOENCODER_SAMPLES, 'rb'))\n",
    "x_train /= 255.0\n",
    "x_val /= 255.0\n",
    "\n",
    "print(x_train.shape, x_train.dtype, x_train.min(), x_train.max())\n",
    "print(x_val.shape, x_val.dtype, x_val.min(), x_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(idx, prev_input, filters, activation='relu', name=None):\n",
    "    conv_name = 'conv_' + str(idx)\n",
    "    bn_name = 'bn_' + str(idx)\n",
    "    act_name = f'{activation}_' + str(idx) if name is None else name\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=None, name=conv_name)(prev_input)\n",
    "    conv = BatchNormalization(axis=-1, name=bn_name)(conv)\n",
    "    conv = Activation(activation, name=act_name)(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def conv_bn_maxpool(idx, prev_input, filters):\n",
    "    pool_name = 'pool_' + str(idx)\n",
    "    \n",
    "    conv = conv_bn(idx, prev_input, filters)\n",
    "    pool = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name=pool_name)(conv)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def deconv_bn(idx, prev_input, filters, activation='relu'):\n",
    "    bn_name = str(idx) + '_bn' \n",
    "    act_name = str(idx) + '_relu' \n",
    "    conv_name = str(idx) + '_conv' \n",
    "    \n",
    "    deconv = Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2, 2), padding='same', activation=None, name=conv_name)(prev_input)\n",
    "    deconv = BatchNormalization(axis=-1, name=bn_name)(deconv)\n",
    "    deconv = Activation(activation, name=act_name)(deconv)\n",
    "    return deconv\n",
    "\n",
    "\n",
    "def dense_layer(idx, prev_input, units, dropout=True, rate=0.5, activation='relu'):\n",
    "    dense_name = f\"dense_{idx}\"\n",
    "    drop_name = f\"dropout_{idx}\"\n",
    "    \n",
    "    if dropout:\n",
    "        prev_input = Dropout(rate, name=drop_name)(prev_input)\n",
    "    out = Dense(units, activation=activation, name=dense_name)(prev_input)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = IMAGE_SIZE\n",
    "n_channels = 3\n",
    "\n",
    "def sample_z(args):\n",
    "    mu, sigma = args\n",
    "    batch_size = K.shape(mu)[0]\n",
    "    latent_dim = K.int_shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return mu + K.exp(0.5 * sigma) * eps\n",
    "\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
    "    https://www.machinecurve.com/index.php/2019/12/30/how-to-create-a-variational-autoencoder-with-keras/\n",
    "    \"\"\"\n",
    "    reconstruction_loss = mse(K.flatten(y_true), K.flatten(y_pred))\n",
    "    reconstruction_loss *= (img_width * img_height)\n",
    "    \n",
    "    kl_loss = 1 + z_sigma - K.square(z_mean) - K.exp(z_sigma)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "\n",
    "# def vae_loss(y_true, y_pred):\n",
    "#     \"\"\"https://keras.io/examples/generative/vae/#define-the-vae-as-a-model-with-a-custom-trainstep\"\"\"\"\n",
    "#     reconstruction_loss = tf.reduce_mean(binary_crossentropy(y_true, y_pred))\n",
    "#     reconstruction_loss *= (img_width * img_height)\n",
    "    \n",
    "#     kl_loss = 1 + z_sigma - tf.square(z_mean) - tf.exp(z_sigma)\n",
    "#     kl_loss = tf.reduce_mean(kl_loss)\n",
    "#     kl_loss *= -0.5\n",
    "#     return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pdist_euclidean(A):\n",
    "    # Euclidean pdist\n",
    "    # https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow\n",
    "    r = tf.reduce_sum(A*A, 1)\n",
    "\n",
    "    # turn r into column vector\n",
    "    r = tf.reshape(r, [-1, 1])\n",
    "    D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
    "    return tf.sqrt(D)\n",
    "\n",
    "\n",
    "def square_to_vec(D):\n",
    "    '''Convert a squared form pdist matrix to vector form.'''\n",
    "    ones = tf.ones_like(D)\n",
    "    mask_a = tf.matrix_band_part(ones, 0, -1) # Upper triangular matrix of 0s and 1s\n",
    "    mask_b = tf.matrix_band_part(ones, 0, 0)  # Diagonal matrix of 0s and 1s\n",
    "    mask = tf.cast(mask_a - mask_b, dtype=tf.bool) # Make a bool mask\n",
    "\n",
    "    upper_triangular = tf.boolean_mask(D, mask)\n",
    "    return upper_triangular\n",
    "\n",
    "\n",
    "def get_contrast_batch_labels(y):\n",
    "    '''\n",
    "    Make contrast labels by taking all the pairwise in y\n",
    "    y: tensor with shape: (batch_size, )\n",
    "    returns:   \n",
    "        tensor with shape: (batch_size * (batch_size-1) // 2, )\n",
    "    '''\n",
    "    y = tf.reduce_sum(y*y, 1)\n",
    "    y_col_vec = tf.reshape(tf.cast(y, tf.float32), [-1, 1])\n",
    "    D_y = pdist_euclidean(y_col_vec)\n",
    "    d_y = square_to_vec(D_y)\n",
    "    y_contrasts = tf.cast(tf.equal(d_y, tf.zeros_like(d_y)), tf.int32)\n",
    "    return y_contrasts\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    r\"\"\"Computes the contrastive loss between `y_true` and `y_pred`.\n",
    "    This loss encourages the embedding to be close to each other for\n",
    "    the samples of the same label and the embedding to be far apart at least\n",
    "    by the margin constant for the samples of different labels.\n",
    "    The euclidean distances `y_pred` between two embedding matrices\n",
    "    `a` and `b` with shape [batch_size, hidden_size] can be computed\n",
    "    as follows:\n",
    "    ```python\n",
    "    # y_pred = \\sqrt (\\sum_i (a[:, i] - b[:, i])^2)\n",
    "    y_pred = tf.linalg.norm(a - b, axis=1)\n",
    "    ```\n",
    "    See: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    Args:\n",
    "      y_true: 1-D integer `Tensor` with shape [batch_size] of\n",
    "        binary labels indicating positive vs negative pair.\n",
    "      y_pred: 1-D float `Tensor` with shape [batch_size] of\n",
    "        distances between two embedding matrices.\n",
    "      margin: margin term in the loss definition.\n",
    "    Returns:\n",
    "      contrastive_loss: 1-D float `Tensor` with shape [batch_size].\n",
    "    \"\"\"\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.dtypes.cast(y_true, y_pred.dtype)\n",
    "    return y_true * tf.math.square(y_pred) + (1.0 - y_true) * tf.math.square(\n",
    "        tf.math.maximum(margin - y_pred, 0.0)\n",
    "    )\n",
    "\n",
    "\n",
    "# def contrastive_loss(y_true, y_pred):\n",
    "#     '''Contrastive loss from Hadsell-et-al.'06\n",
    "#     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "#     '''\n",
    "#     margin = 1\n",
    "#     return K.mean(y_true * K.square(y_pred) +\n",
    "#                   (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def max_margin_contrastive_loss(y, z, margin=1.0, metric='euclidean'):\n",
    "    '''\n",
    "    Wrapper for the maximum margin contrastive loss (Hadsell et al. 2006)\n",
    "    `tfa.losses.contrastive_loss`\n",
    "    Args:\n",
    "        y: ground truth of shape [bsz].\n",
    "        z: hidden vector of shape [bsz, n_features].\n",
    "        metric: one of ('euclidean', 'cosine')\n",
    "    '''\n",
    "    # compute pair-wise distance matrix\n",
    "    if metric == 'euclidean':\n",
    "        D = pdist_euclidean(z)\n",
    "    elif metric == 'cosine':\n",
    "        D = 1 - tf.matmul(z, z, transpose_a=False, transpose_b=True)\n",
    "    # convert squareform matrix to vector form\n",
    "    d_vec = square_to_vec(D)\n",
    "    # make contrastive labels\n",
    "    y_contrasts = get_contrast_batch_labels(y)\n",
    "    loss = contrastive_loss(y_contrasts, d_vec, margin=margin)\n",
    "    # exploding/varnishing gradients on large batch?\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "class UnitNormLayer(Layer):\n",
    "    '''Normalize vectors (euclidean norm) in batch to unit hypersphere.'''\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super(UnitNormLayer, self).__init__(name=name)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        norm = tf.norm(input_tensor, axis=1)\n",
    "        return input_tensor / tf.reshape(norm, [-1, 1])\n",
    "\n",
    "# y_true = np.random.randint(0, 2, (4, 5))\n",
    "# y_pred = tf.random_normal((4, 5))\n",
    "# K.eval(max_margin_contrastive_loss(y_true, y_pred, metric='cosine'))\n",
    "\n",
    "# y_true = np.random.randint(0, 2, (3, 5))\n",
    "# K.eval(get_contrast_batch_labels(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds()\n",
    "LATENT_DIM = 128\n",
    "N_REQS = y_train.shape[1]\n",
    "\n",
    "# mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "# mlflow.log_param(\"test_size\", TEST_SIZE)\n",
    "# mlflow.log_param(\"seed\", RANDOM_SEED)\n",
    "# mlflow.log_param(\"latent_dim\", LATENT_DIM)\n",
    "# mlflow.keras.autolog()\n",
    "\n",
    "# encoder\n",
    "inputs = Input(shape=x_train.shape[1:], name='input')\n",
    "pool_1 = conv_bn_maxpool(1, inputs, 16)\n",
    "pool_2 = conv_bn_maxpool(2, pool_1, 32)\n",
    "pool_3 = conv_bn_maxpool(3, pool_2, 64)\n",
    "pool_4 = conv_bn_maxpool(4, pool_3, 128)\n",
    "conv_shape = K.int_shape(pool_4)\n",
    "\n",
    "avg_pool = GlobalAvgPool2D(name='global_avg_pool')(pool_4)\n",
    "z_mean = Dense(LATENT_DIM, name='z_mean')(avg_pool)\n",
    "z_sigma = Dense(LATENT_DIM, name='z_sigma')(avg_pool)\n",
    "z = Lambda(sample_z, output_shape=(LATENT_DIM, ), name='embeddings')([z_mean, z_sigma])\n",
    "\n",
    "# decoder\n",
    "dense = Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu', name='dense')(z)\n",
    "reshape = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name='reshape')(dense)\n",
    "dec_4 = deconv_bn(4, reshape, 128)\n",
    "dec_3 = deconv_bn(3, dec_4, 64)\n",
    "dec_2 = deconv_bn(2, dec_3, 32)\n",
    "dec_1 = deconv_bn(1, dec_2, 16)\n",
    "decoded = Conv2D(filters=3, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='sigmoid', name='decoded')(dec_1)\n",
    "\n",
    "# projector\n",
    "proj_1 = Dense(units=LATENT_DIM, activation='relu', name='proj_1')(z_mean)\n",
    "proj_2 = Dense(units=N_REQS, activation='sigmoid', name='proj_2')(proj_1)\n",
    "project = UnitNormLayer(name='project')(proj_2)\n",
    "\n",
    "# classifier\n",
    "dense_1 = dense_layer(1, z_mean, 32)\n",
    "classif = Dense(units=N_REQS, activation='sigmoid', name='outputs')(dense_1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[decoded, project, classif], name='ICAOnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODED_LOSS_WEIGHT = 1.0\n",
    "OUTPUTS_LOSS_WEIGHT = 1.0\n",
    "PROJECT_LOSS_WEIGHT = 1.0\n",
    "\n",
    "# mlflow.log_param(\"decoded loss weight\", DECODED_LOSS_WEIGHT)\n",
    "# mlflow.log_param(\"outputs loss weight\", OUTPUTS_LOSS_WEIGHT)\n",
    "# mlflow.log_param(\"project loss weight\", PROJECT_LOSS_WEIGHT)\n",
    "\n",
    "losses = {\n",
    "    \"decoded\": vae_loss,\n",
    "    \"outputs\": \"binary_crossentropy\",\n",
    "    \"project\": max_margin_contrastive_loss,\n",
    "}\n",
    "\n",
    "loss_weights = {\n",
    "    \"decoded\": DECODED_LOSS_WEIGHT,\n",
    "    \"outputs\": OUTPUTS_LOSS_WEIGHT,\n",
    "    \"project\": PROJECT_LOSS_WEIGHT,\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"outputs\": [\"accuracy\", precision, recall, f1, fbeta, specificity, npv, mcc]\n",
    "}\n",
    "METRIC_TO_MONITOR = \"val_outputs_fbeta\"\n",
    "\n",
    "outputs_train = {\n",
    "    \"decoded\": x_train,\n",
    "    \"outputs\": y_train,\n",
    "    \"project\": y_train,\n",
    "}\n",
    "\n",
    "outputs_valid = {\n",
    "    \"decoded\": x_val,\n",
    "    \"outputs\": y_val,\n",
    "    \"project\": y_val,\n",
    "}\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights, metrics=metrics)\n",
    "\n",
    "FILE_MODEL = FOLDER_MODELS + timestamp_model_name(prefix=\"multilearner_\")\n",
    "list_callbacks = [\n",
    "    ModelCheckpoint(FILE_MODEL, monitor=METRIC_TO_MONITOR, mode=\"max\", verbose=1, save_best_only=True), \n",
    "    EarlyStopping(monitor=METRIC_TO_MONITOR, mode=\"max\", patience=50, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    x=x_train,\n",
    "    y=outputs_train,\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    validation_data=(x_val, outputs_valid),\n",
    "#     callbacks=list_callbacks\n",
    ")\n",
    "\n",
    "plot.keras_hist(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = hist.history\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['outputs_matthews_correlation_coefficient'], label='train')\n",
    "plt.plot(history['val_outputs_matthews_correlation_coefficient'], label='val')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['outputs_fbeta'], label='train')\n",
    "plt.plot(history['val_outputs_fbeta'], label='val')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.choice(x_val.shape[0])\n",
    "im = np.expand_dims(x_val[random_idx], axis=0)\n",
    "y_true = y_val[random_idx] \n",
    "\n",
    "y_pred_decoded, y_pred_outputs = model.predict(im)\n",
    "y_pred_outputs = np.where(y_pred_outputs > 0.5, 1, 0)\n",
    "\n",
    "print(y_true, y_pred_outputs[0], sep='\\n')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im.squeeze()[:, :, ::-1])\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y_pred_decoded.squeeze()[:, :, ::-1])\n",
    "plt.title('decoded image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MODEL_CLF = FILE_MODEL.replace('multilearner', 'model')\n",
    "print(FILE_MODEL_CLF)\n",
    "\n",
    "model_clf = Model(inputs=model.inputs, outputs=model.get_layer('outputs').output, name=\"ICAOnet\")\n",
    "model_clf.summary()\n",
    "\n",
    "model_clf.save(FILE_MODEL_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "model_clf = load_model(FILE_MODEL_CLF)\n",
    "\n",
    "list_files = [PATH_TO_ROOT + 'data/cropped_faces/images/AR_FDB_m-013-17.png']\n",
    "random_file = np.random.choice(list_files)\n",
    "print(random_file)\n",
    "\n",
    "im = load.images_from_list_files([random_file], output_size=IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "im /= 255\n",
    "\n",
    "y_pred_ori = model.predict(im)[1]\n",
    "y_pred_clf = model_clf.predict(im)\n",
    "assert(np.allclose(y_pred_ori, y_pred_clf))\n",
    "\n",
    "for y_pred in y_pred_clf[0]:\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_LOGS = '../../logs/unsupervised_supervised/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image_files = pkl.load(open(FILE_DUMP_IMAGES, 'rb'))\n",
    "_, data, _, mrks = pkl.load(open(FILE_AUTOENCODER_SAMPLES, 'rb'))\n",
    "\n",
    "image_files = [basename(filepath) for filepath in np.array(image_files)[x_val_idx]]\n",
    "print(len(image_files))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{FOLDER_LOGS}/metadata.tsv', 'w') as metadata_file:\n",
    "    for file in image_files:\n",
    "        metadata_file.write(file+'\\n')\n",
    "\n",
    "mlflow.log_artifact(f'{FOLDER_LOGS}/metadata.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Sprite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min_data = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min_data).transpose(3,0,1,2)\n",
    "    max_data = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max_data).transpose(3,0,1,2)\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data### Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sprite = images_to_sprite(data)\n",
    "print(im_sprite.shape)\n",
    "\n",
    "cv2.imwrite(f'{FOLDER_LOGS}/sprites.png', im_sprite)\n",
    "mlflow.log_artifact(f'{FOLDER_LOGS}/sprites.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(FILE_MODEL_CLF)\n",
    "\n",
    "embeddings = GlobalAvgPool2D(name='embeddings')(model.get_layer(name='encoded').output)\n",
    "\n",
    "model_emb = Model(inputs=model.inputs, outputs=embeddings)\n",
    "model_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vectors = model_emb.predict(data)\n",
    "print(emb_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf_embeddings = tf.Variable(emb_vectors, name='embeddings')\n",
    "summary_writer = tf.summary.FileWriter(f'{FOLDER_LOGS}')\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = tf_embeddings.name\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "embedding.sprite.image_path = 'sprites.png'\n",
    "embedding.sprite.single_image_dim.extend(IMAGE_SIZE)\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "saver = tf.train.Saver([tf_embeddings])\n",
    "sess.run(tf_embeddings.initializer)\n",
    "saver.save(sess, f'{FOLDER_LOGS}/embeddings.ckpt')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
