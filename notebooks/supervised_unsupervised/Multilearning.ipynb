{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('..')\n",
    "path.append('../../src/')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from os.path import basename, join\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, GlobalAvgPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE, FILE_DUMP_IMAGES, FILE_DUMP_MRKS\n",
    "from local_config import FOLDER_MODELS, FILE_AUTOENCODER_SAMPLES\n",
    "from custom_metrics import precision, recall, f1, specificity, fbeta\n",
    "from custom_metrics import negative_predictive_value as npv \n",
    "from custom_metrics import matthews_correlation_coefficient as mcc\n",
    "from utils import plot, load\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ROOT = '../../'\n",
    "\n",
    "FOLDER_LOGS = join(PATH_TO_ROOT, 'logs')\n",
    "FOLDER_MODELS = join(PATH_TO_ROOT, FOLDER_MODELS)\n",
    "FILE_DUMP_MRKS = join(PATH_TO_ROOT, FILE_DUMP_MRKS)\n",
    "FILE_DUMP_IMAGES = join(PATH_TO_ROOT, FILE_DUMP_IMAGES)\n",
    "FILE_AUTOENCODER_SAMPLES = join(PATH_TO_ROOT, FILE_AUTOENCODER_SAMPLES)\n",
    "\n",
    "print(FOLDER_LOGS)\n",
    "print(FOLDER_MODELS)\n",
    "print(FILE_DUMP_MRKS)\n",
    "print(FILE_DUMP_IMAGES)\n",
    "print(FILE_AUTOENCODER_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "MLFLOW_EXPERIMENT_NAME = 'Unsupervised + Supervised'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_model_name(prefix='model_', suffix='', format='%Y_%m_%d-%H_%M_%S', ext='.h5'):\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(format)\n",
    "    return f'{prefix}{timestamp}{suffix}{ext}'\n",
    "\n",
    "\n",
    "def set_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    rn.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = pkl.load(open(FILE_DUMP_IMAGES, 'rb'))\n",
    "mrks, _ = pkl.load(open(FILE_DUMP_MRKS, 'rb'))\n",
    "y = np.array([mrk_file.photo_reqs.values() for mrk_file in mrks])\n",
    "\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)\n",
    "print(len(mrks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "x_train_idx, y_train, x_val_idx, y_val = iterative_train_test_split(np.arange(x.shape[0]).reshape(-1, 1), y, test_size=TEST_SIZE)\n",
    "x_train_idx = x_train_idx.ravel()\n",
    "x_val_idx = x_val_idx.ravel()\n",
    "\n",
    "x_train = x[x_train_idx]\n",
    "x_val = x[x_val_idx]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mrks = mrks[x_train_idx]\n",
    "val_mrks = mrks[x_val_idx]\n",
    "\n",
    "# pkl.dump((x_train, x_val, train_mrks, val_mrks), open(FILE_AUTOENCODER_SAMPLES, 'wb'), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, _, _ = pkl.load(open(FILE_AUTOENCODER_SAMPLES, 'rb'))\n",
    "x_train /= 255.0\n",
    "x_val /= 255.0\n",
    "\n",
    "print(x_train.shape, x_train.dtype, x_train.min(), x_train.max())\n",
    "print(x_val.shape, x_val.dtype, x_val.min(), x_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(idx, prev_input, filters, activation='relu', name=None):\n",
    "    conv_name = 'conv_' + str(idx)\n",
    "    bn_name = 'bn_' + str(idx)\n",
    "    act_name = f'{activation}_' + str(idx) if name is None else name\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=None, name=conv_name)(prev_input)\n",
    "    conv = BatchNormalization(axis=-1, name=bn_name)(conv)\n",
    "    conv = Activation(activation, name=act_name)(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def conv_bn_maxpool(idx, prev_input, filters):\n",
    "    pool_name = 'pool_' + str(idx)\n",
    "    \n",
    "    conv = conv_bn(idx, prev_input, filters)\n",
    "    pool = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid', name=pool_name)(conv)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def deconv_bn(idx, prev_input, filters, activation='relu'):\n",
    "    bn_name = str(idx) + '_bn' \n",
    "    act_name = str(idx) + '_relu' \n",
    "    conv_name = str(idx) + '_conv' \n",
    "    \n",
    "    deconv = Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2, 2), padding='same', activation=None, name=conv_name)(prev_input)\n",
    "    deconv = BatchNormalization(axis=-1, name=bn_name)(deconv)\n",
    "    deconv = Activation(activation, name=act_name)(deconv)\n",
    "    return deconv\n",
    "\n",
    "\n",
    "def dense_layer(idx, prev_input, units, dropout=True, rate=0.5, activation='relu'):\n",
    "    dense_name = f\"dense_{idx}\"\n",
    "    drop_name = f\"dropout_{idx}\"\n",
    "    \n",
    "    if dropout:\n",
    "        prev_input = Dropout(rate)(prev_input)\n",
    "    out = Dense(units, activation=activation)(prev_input)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "mlflow.log_param(\"test_size\", TEST_SIZE)\n",
    "mlflow.log_param(\"seed\", RANDOM_SEED)\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "set_random_seeds()\n",
    "N_REQS = y_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=x_train.shape[1:], name='input')\n",
    "pool_1 = conv_bn_maxpool(1, inputs, 32)\n",
    "pool_2 = conv_bn_maxpool(2, pool_1, 64)\n",
    "pool_3 = conv_bn_maxpool(3, pool_2, 128)\n",
    "pool_4 = conv_bn_maxpool(4, pool_3, 256)\n",
    "encode = conv_bn(5, pool_4, 256, activation='tanh', name='encoded')\n",
    "\n",
    "dec_4 = deconv_bn(4, encode, 256)\n",
    "dec_3 = deconv_bn(3, dec_4, 128)\n",
    "dec_2 = deconv_bn(2, dec_3, 64)\n",
    "dec_1 = deconv_bn(1, dec_2, 32)\n",
    "decoded = Conv2D(filters=3, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='sigmoid', name='decoded')(dec_1)\n",
    "\n",
    "avg_pool = GlobalAvgPool2D()(encode)\n",
    "dense_1 = dense_layer(1, avg_pool, 64)\n",
    "dense_2 = dense_layer(2, dense_1, 32)\n",
    "classif = Dense(units=N_REQS, activation='sigmoid', name='outputs')(dense_2)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[decoded, classif])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DECODED_LOSS_WEIGHT = 2.0\n",
    "OUTPUTS_LOSS_WEIGHT = 1.0\n",
    "\n",
    "mlflow.log_param(\"decoded loss weight\", DECODED_LOSS_WEIGHT)\n",
    "mlflow.log_param(\"outputs loss weight\", OUTPUTS_LOSS_WEIGHT)\n",
    "\n",
    "losses = {\n",
    "    \"decoded\": \"mean_squared_error\",\n",
    "    \"outputs\": \"binary_crossentropy\"\n",
    "}\n",
    "\n",
    "loss_weights = {\n",
    "    \"decoded\": DECODED_LOSS_WEIGHT,\n",
    "    \"outputs\": OUTPUTS_LOSS_WEIGHT\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"outputs\": [\"accuracy\", precision, recall, f1, fbeta, specificity, npv, mcc]\n",
    "}\n",
    "METRIC_TO_MONITOR = \"val_outputs_fbeta\"\n",
    "\n",
    "outputs_train = {\n",
    "    \"decoded\": x_train,\n",
    "    \"outputs\": y_train\n",
    "}\n",
    "\n",
    "outputs_valid = {\n",
    "    \"decoded\": x_val,\n",
    "    \"outputs\": y_val\n",
    "}\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights, metrics=metrics)\n",
    "\n",
    "FILE_MODEL = FOLDER_MODELS + timestamp_model_name(prefix=\"multilearner_\")\n",
    "list_callbacks = [\n",
    "    ModelCheckpoint(FILE_MODEL, monitor=METRIC_TO_MONITOR, mode=\"max\", verbose=1, save_best_only=True), \n",
    "    EarlyStopping(monitor=METRIC_TO_MONITOR, mode=\"max\", patience=30, verbose=1, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    x=x_train,\n",
    "    y=outputs_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(x_val, outputs_valid),\n",
    "    callbacks=list_callbacks\n",
    ")\n",
    "\n",
    "plot.keras_hist(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = hist.history\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['outputs_matthews_correlation_coefficient'], label='train')\n",
    "plt.plot(history['val_outputs_matthews_correlation_coefficient'], label='val')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['outputs_fbeta'], label='train')\n",
    "plt.plot(history['val_outputs_fbeta'], label='val')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.choice(x_val.shape[0])\n",
    "im = np.expand_dims(x_val[random_idx], axis=0)\n",
    "y_true = y_val[random_idx] \n",
    "\n",
    "y_pred_decoded, y_pred_outputs = model.predict(im)\n",
    "y_pred_outputs = np.where(y_pred_outputs > 0.5, 1, 0)\n",
    "\n",
    "print(y_true, y_pred_outputs[0], sep='\\n')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im.squeeze()[:, :, ::-1])\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y_pred_decoded.squeeze()[:, :, ::-1])\n",
    "plt.title('decoded image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MODEL_CLF = FILE_MODEL.replace('multilearner', 'model')\n",
    "print(FILE_MODEL_CLF)\n",
    "\n",
    "model_clf = Model(inputs=model.inputs, outputs=model.get_layer('outputs').output, name=\"ICAOnet\")\n",
    "model_clf.summary()\n",
    "\n",
    "model_clf.save(FILE_MODEL_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "model_clf = load_model(FILE_MODEL_CLF)\n",
    "\n",
    "list_files = [PATH_TO_ROOT + 'data/cropped_faces/images/AR_FDB_m-013-17.png']\n",
    "random_file = np.random.choice(list_files)\n",
    "print(random_file)\n",
    "\n",
    "im = load.images_from_list_files([random_file], output_size=IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "im /= 255\n",
    "\n",
    "y_pred_ori = model.predict(im)[1]\n",
    "y_pred_clf = model_clf.predict(im)\n",
    "assert(np.allclose(y_pred_ori, y_pred_clf))\n",
    "\n",
    "for y_pred in y_pred_clf[0]:\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_LOGS = '../../logs/unsupervised_supervised/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image_files = pkl.load(open(FILE_DUMP_IMAGES, 'rb'))\n",
    "_, data, _, mrks = pkl.load(open(FILE_AUTOENCODER_SAMPLES, 'rb'))\n",
    "\n",
    "image_files = [basename(filepath) for filepath in np.array(image_files)[x_val_idx]]\n",
    "print(len(image_files))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{FOLDER_LOGS}/metadata.tsv', 'w') as metadata_file:\n",
    "    for file in image_files:\n",
    "        metadata_file.write(file+'\\n')\n",
    "\n",
    "mlflow.log_artifact(f'{FOLDER_LOGS}/metadata.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Sprite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min_data = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min_data).transpose(3,0,1,2)\n",
    "    max_data = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max_data).transpose(3,0,1,2)\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data### Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sprite = images_to_sprite(data)\n",
    "print(im_sprite.shape)\n",
    "\n",
    "cv2.imwrite(f'{FOLDER_LOGS}/sprites.png', im_sprite)\n",
    "mlflow.log_artifact(f'{FOLDER_LOGS}/sprites.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(FILE_MODEL_CLF)\n",
    "\n",
    "embeddings = GlobalAvgPool2D(name='embeddings')(model.get_layer(name='encoded').output)\n",
    "\n",
    "model_emb = Model(inputs=model.inputs, outputs=embeddings)\n",
    "model_emb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vectors = model_emb.predict(data)\n",
    "print(emb_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf_embeddings = tf.Variable(emb_vectors, name='embeddings')\n",
    "summary_writer = tf.summary.FileWriter(f'{FOLDER_LOGS}')\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = tf_embeddings.name\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "embedding.sprite.image_path = 'sprites.png'\n",
    "embedding.sprite.single_image_dim.extend(IMAGE_SIZE)\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "saver = tf.train.Saver([tf_embeddings])\n",
    "sess.run(tf_embeddings.initializer)\n",
    "saver.save(sess, f'{FOLDER_LOGS}/embeddings.ckpt')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
