{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from time import time\n",
    "from global_config import FOLDER_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5763\n"
     ]
    }
   ],
   "source": [
    "list_images = glob(FOLDER_IMAGES + \"*\")\n",
    "n_images = len(list_images)\n",
    "\n",
    "print(n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_pb(pb_file):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(open(pb_file, 'rb').read())\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "def load_graph_from_meta(model_dir, meta_file, checkpoint_prefix=None):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph(model_dir+meta_file)\n",
    "        if checkpoint_prefix is None:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "        else:\n",
    "            saver.restore(sess, model_dir + checkpoint_prefix)\n",
    "        graph = tf.get_default_graph()\n",
    "    return graph\n",
    "\n",
    "def save_graph(graph, output_file, as_pbtxt=False):\n",
    "    folder, file = split(output_file)\n",
    "    tf.train.write_graph(graph, logdir=folder, name=file, as_text=as_pbtxt)\n",
    "    \n",
    "def get_graph_node_names(graph):\n",
    "    return [node.name for node in graph.as_graph_def().node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TropComplique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'C:/Users/arnal/Downloads/face_detectors/trop_complique.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector:\n",
    "    def __init__(self, model_path, gpu_memory_fraction=0.25, visible_device_list='0'):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            model_path: a string, path to a pb file.\n",
    "            gpu_memory_fraction: a float number.\n",
    "            visible_device_list: a string.\n",
    "        \"\"\"\n",
    "        with tf.gfile.GFile(model_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            tf.import_graph_def(graph_def, name='import')\n",
    "\n",
    "        self.input_image = graph.get_tensor_by_name('import/image_tensor:0')\n",
    "        self.output_ops = [\n",
    "            graph.get_tensor_by_name('import/boxes:0'),\n",
    "            graph.get_tensor_by_name('import/scores:0'),\n",
    "            graph.get_tensor_by_name('import/num_boxes:0'),\n",
    "        ]\n",
    "\n",
    "        gpu_options = tf.GPUOptions(\n",
    "            per_process_gpu_memory_fraction=gpu_memory_fraction,\n",
    "            visible_device_list=visible_device_list\n",
    "        )\n",
    "        config_proto = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False)\n",
    "        self.sess = tf.Session(graph=graph, config=config_proto)\n",
    "\n",
    "    def __call__(self, image, score_threshold=0.5):\n",
    "        \"\"\"Detect faces.\n",
    "\n",
    "        Arguments:\n",
    "            image: a numpy uint8 array with shape [height, width, 3],\n",
    "                that represents a RGB image.\n",
    "            score_threshold: a float number.\n",
    "        Returns:\n",
    "            boxes: a float numpy array of shape [num_faces, 4].\n",
    "            scores: a float numpy array of shape [num_faces].\n",
    "\n",
    "        Note that box coordinates are in the order: ymin, xmin, ymax, xmax!\n",
    "        \"\"\"\n",
    "        h, w, _ = image.shape\n",
    "        image = np.expand_dims(image, 0)\n",
    "\n",
    "        boxes, scores, num_boxes = self.sess.run(\n",
    "            self.output_ops, feed_dict={self.input_image: image}\n",
    "        )\n",
    "        num_boxes = num_boxes[0]\n",
    "        boxes = boxes[0][:num_boxes]\n",
    "        scores = scores[0][:num_boxes]\n",
    "\n",
    "        to_keep = scores > score_threshold\n",
    "        boxes = boxes[to_keep]\n",
    "        scores = scores[to_keep]\n",
    "\n",
    "        scaler = np.array([h, w, h, w], dtype='float32')\n",
    "        boxes = boxes * scaler\n",
    "\n",
    "        return boxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image_array = cv2.imread(path)\n",
    "    image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "    return image_array\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, scores):\n",
    "    image_copy = image.copy()\n",
    "    draw = ImageDraw.Draw(image_copy, 'RGBA')\n",
    "    width, height = image.size\n",
    "\n",
    "    for b, s in zip(boxes, scores):\n",
    "        ymin, xmin, ymax, xmax = b\n",
    "        fill = (255, 0, 0, 45)\n",
    "        outline = 'red'\n",
    "        draw.rectangle(\n",
    "            [(xmin, ymin), (xmax, ymax)],\n",
    "            fill=fill, outline=outline\n",
    "        )\n",
    "        draw.text((xmin, ymin), text='{:.3f}'.format(s))\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Detections: 5746 of 5763\n",
      "Avg Time (s): 0.11038639333209664\n"
     ]
    }
   ],
   "source": [
    "n_detected = 0\n",
    "\n",
    "face_detector = FaceDetector(MODEL_PATH, gpu_memory_fraction=0.0, visible_device_list='0')\n",
    "\n",
    "start = time()\n",
    "for i, image_path in enumerate(list_images, start=1):\n",
    "    print(f'{i} of {n_images}', end='\\r')\n",
    "    \n",
    "    im = load_image(image_path)\n",
    "    boxes, scores = face_detector(im, score_threshold=0.3)\n",
    "    if len(boxes) > 0:\n",
    "        n_detected += 1\n",
    "end = time()\n",
    "\n",
    "avg_time = (end - start) / n_images\n",
    "\n",
    "print(f'Total Detections: {n_detected} of {n_images}')\n",
    "print('Avg Time (s):', avg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/arnal/Downloads/face_detectors/run00/model.ckpt-240000\n"
     ]
    }
   ],
   "source": [
    "from os.path import split\n",
    "\n",
    "graph = load_graph_from_meta(\"C:/Users/arnal/Downloads/face_detectors/run00/\", \"model.ckpt-240000.meta\")\n",
    "save_graph(graph, \"C:/Users/arnal/Downloads/face_detectors/run00/frozen_graph.pb\")\n",
    "save_graph(graph, \"C:/Users/arnal/Downloads/face_detectors/run00/frozen_graph.pbtxt\", as_pbtxt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph_from_pb(MODEL_PATH)\n",
    "# graph = load_graph_from_meta(\"C:/Users/arnal/Downloads/face_detectors/run00/\", \"model.ckpt-240000.meta\")\n",
    "name_list = get_graph_node_names(graph)\n",
    "\n",
    "with open('name-list.txt', 'w') as file:\n",
    "    for name in name_list:\n",
    "        file.write(name+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeephycho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'C:/Users/arnal/Downloads/face_detectors/yeephycho.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_pb(pb_file):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(open(pb_file, 'rb').read())\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "def run_graph(graph, inputs_list, input_tensor_names, output_tensor_names):\n",
    "    assert(len(inputs_list) == len(input_tensor_names))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        input_tensors = [graph.get_tensor_by_name(name) for name in input_tensor_names]\n",
    "        output_tensors = [graph.get_tensor_by_name(name) for name in output_tensor_names]\n",
    "        feed_dict = {tensor:value for tensor, value in zip(input_tensors, inputs_list)}\n",
    "        return sess.run(output_tensors, feed_dict=feed_dict)\n",
    "\n",
    "class Rect():\n",
    "    def __init__(self, x, y, width=None, height=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def from_tl_br_points(tl, br):\n",
    "        return Rect(tl[0], tl[1], br[0] - tl[0], br[1] - tl[1])\n",
    "\n",
    "    def tl(self):\n",
    "        '''return upper left point (x, y)'''\n",
    "        return (self.x, self.y)\n",
    "\n",
    "    def br(self):\n",
    "        '''return bottom right point (x, y)'''\n",
    "        return (self.x + self.width, self.y + self.height)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '(x, y, width, height): ({}, {}, {}, {})'.format(self.x, self.y, self.width, self.height)\n",
    "\n",
    "class Yeephycho():\n",
    "    def __init__(self, conf_threshold=0.1):\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.graph = load_graph_from_pb(MODEL_PATH)\n",
    "\n",
    "    def detect(self, image_file, det_size=(512, 512)):\n",
    "        det_size = (512, 512)\n",
    "        im = cv2.imread(image_file, cv2.IMREAD_COLOR)\n",
    "        h, w = im.shape[:2]\n",
    "#         im = cv2.resize(im, det_size)\n",
    "\n",
    "        inputs_list = [np.expand_dims(im, axis=0)]\n",
    "        input_tensor_names = ['import/image_tensor:0']\n",
    "        output_tensor_names = ['import/detection_boxes:0', 'import/detection_scores:0']\n",
    "        boxes, scores = run_graph(self.graph, inputs_list, input_tensor_names, output_tensor_names)\n",
    "\n",
    "        boxes = boxes[scores > self.conf_threshold]\n",
    "        return [\n",
    "            Rect.from_tl_br_points(\n",
    "                (int(x1 * w), int(y1 * h)),\n",
    "                (int(x2 * w), int(y2 * h))\n",
    "            ) \n",
    "            for y1, x1, y2, x2 in boxes\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Detections: 5705 of 5763\n",
      "Avg Time (s): 1.8717303832909846\n"
     ]
    }
   ],
   "source": [
    "n_detected = 0\n",
    "\n",
    "face_detector = Yeephycho()\n",
    "\n",
    "start = time()\n",
    "for i, image_path in enumerate(list_images, start=1):\n",
    "    print(f'{i} of {n_images}', end='\\r')\n",
    "    \n",
    "    rects = face_detector.detect(image_path)\n",
    "    if len(rects) > 0:\n",
    "        n_detected += 1\n",
    "end = time()\n",
    "\n",
    "avg_time = (end - start) / n_images\n",
    "\n",
    "print(f'Total Detections: {n_detected} of {n_images}')\n",
    "print('Avg Time (s):', avg_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'C:/Users/arnal/Downloads/face_detectors/faced.pb'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
