{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:823: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\n",
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\data_structures.py:312: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  class _ListWrapper(List, collections.MutableSequence,\n",
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\util.py:448: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  class _ObjectIdentitySet(collections.MutableSet):\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\arnal\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\callbacks\\callbacks.py:19: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle as pkl\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Conv2D, GlobalAvgPool2D\n",
    "from keras.layers import Dense, Dropout, Concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from utils import load, plot\n",
    "from local_config import FOLDER_IMAGES, FOLDER_MODELS\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE\n",
    "from custom_metrics import precision, recall, f1, specificity \n",
    "from custom_metrics import negative_predictive_value as npv \n",
    "from custom_metrics import matthews_correlation_coefficient as mcc\n",
    "from custom_metrics import equal_error_rate as eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/siamese_networks/model_2020_05_23-16_43_01.h5\n",
      "../../data/siamese_networks\n",
      "../../models/siamese_networks\n"
     ]
    }
   ],
   "source": [
    "FILE_BASE_MODEL = '../../models/siamese_networks/model_2020_05_23-16_43_01.h5'\n",
    "FOLDER_POS = \"positives\"\n",
    "FOLDER_NEG = \"negatives\"\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "ALPHA = 2.0\n",
    "MLFLOW_EXPERIMENT_NAME = 'Siamese Networks'\n",
    "\n",
    "print(FILE_BASE_MODEL)\n",
    "print(FOLDER_IMAGES)\n",
    "print(FOLDER_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_model_name(prefix='model_', suffix='', format='%Y_%m_%d-%H_%M_%S', ext='.h5'):\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(format)\n",
    "    return f'{prefix}{timestamp}{suffix}{ext}'\n",
    "\n",
    "def set_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    rn.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "def plot_metrics(y_true, y_pred, hist):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred) \n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    \n",
    "    accuracy_sk = accuracy_score(y_true, y_pred)\n",
    "    precision_sk = precision_score(y_true, y_pred)\n",
    "    recall_sk = recall_score(y_true, y_pred)\n",
    "    f_measure = f1_score(y_true, y_pred)\n",
    "    specificity_sk = tn / (tn + fp + 1e-7)\n",
    "    npv_sk = tn / (tn + fn + 1e-7)\n",
    "    \n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    mcc_sk = num / np.sqrt(den + 1e-7)\n",
    "    \n",
    "    print()\n",
    "    print('   Final Accuracy: {:=6.2f}%'.format(accuracy_sk * 100))\n",
    "    print('  Final Precision: {:=6.2f}%'.format(precision_sk * 100))\n",
    "    print('     Final Recall: {:=6.2f}%'.format(recall_sk * 100))\n",
    "    print('  Final F-measure: {:=6.2f}%'.format(f_measure * 100))\n",
    "    print('Final Specificity: {:=6.2f}%'.format(specificity_sk * 100))\n",
    "    print('        Final NPV: {:=6.2f}%'.format(npv_sk * 100))\n",
    "    print('        Final MCC: {:=6.2f}%'.format(mcc_sk * 100)) \n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    plot.keras_hist(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTripletGenerator(Sequence):\n",
    "    \"\"\"Generate Random Triplets (A, P, N) for Siamese Networks on the fly\"\"\"\n",
    "    def __init__(self, pos_files, neg_files, image_size, emb_dim, batch_size=1, datagen=ImageDataGenerator()):\n",
    "        self.pos_files = pos_files\n",
    "        self.neg_files = neg_files\n",
    "        self.emb_dim = emb_dim\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.datagen = datagen\n",
    "        \n",
    "    def __len__(self):\n",
    "        n_pos = len(self.pos_files)\n",
    "        n_neg = len(self.neg_files)\n",
    "        return min(n_pos, n_neg) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        random_pos = np.random.choice(self.pos_files, size=self.batch_size, replace=False)\n",
    "        random_neg = np.random.choice(self.neg_files, size=self.batch_size, replace=False)\n",
    "        \n",
    "        anchor_set = set(self.neg_files).difference(random_neg)\n",
    "        random_anc = np.random.choice(list(anchor_set), size=self.batch_size, replace=False)\n",
    "        \n",
    "        anc_batch = load.images_from_list_files(random_anc, self.image_size, interpolation=cv2.INTER_AREA, show_progress=False)\n",
    "        pos_batch = load.images_from_list_files(random_pos, self.image_size, interpolation=cv2.INTER_AREA, show_progress=False)\n",
    "        neg_batch = load.images_from_list_files(random_neg, self.image_size, interpolation=cv2.INTER_AREA, show_progress=False)\n",
    "        \n",
    "        anc_batch = self.datagen.flow(anc_batch).next()\n",
    "        pos_batch = self.datagen.flow(pos_batch).next()\n",
    "        neg_batch = self.datagen.flow(neg_batch).next()\n",
    "        \n",
    "        x = [anc_batch, neg_batch, pos_batch]\n",
    "        y = np.zeros(shape=(self.batch_size, 3 * self.emb_dim))\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(alpha=0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "        anc -- the encodings for the anchor data\n",
    "        pos -- the encodings for the positive data\n",
    "        neg -- the encodings for the negative data\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    def loss_func(y_true, y_pred):\n",
    "        total_length = y_pred.shape.as_list()[-1]\n",
    "\n",
    "        anc = y_pred[:, 0:int(total_length * 1/3)]\n",
    "        pos = y_pred[:, int(total_length * 1/3):int(total_length * 2/3)]\n",
    "        neg = y_pred[:, int(total_length * 2/3):int(total_length * 3/3)]\n",
    "        \n",
    "        pos_dist = K.sum(K.square(anc - pos), axis=1)\n",
    "        neg_dist = K.sum(K.square(anc - neg), axis=1)\n",
    "\n",
    "        loss = K.maximum(pos_dist - neg_dist + alpha, 0.0)\n",
    "        return loss\n",
    " \n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 160, 160, 32)      896       \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "relu_1 (Activation)          (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 80, 80, 64)        18496     \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "relu_2 (Activation)          (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 40, 40, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "relu_3 (Activation)          (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 20, 20, 256)       295168    \n",
      "_________________________________________________________________\n",
      "bn_4 (BatchNormalization)    (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "relu_4 (Activation)          (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "pool_4 (MaxPooling2D)        (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "bn_5 (BatchNormalization)    (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "relu_5 (Activation)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "pool_5 (MaxPooling2D)        (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "bn_6 (BatchNormalization)    (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "encoded (Activation)         (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 2,163,648\n",
      "Trainable params: 2,161,152\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(FILE_BASE_MODEL)\n",
    "\n",
    "encoder = Model(inputs=model.inputs, outputs=model.get_layer(name='encoded').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_requirements_model(base_model, name):\n",
    "    set_random_seeds()\n",
    "    \n",
    "    req_emb = GlobalAvgPool2D()(base_model.output)\n",
    "    req_emb = Dropout(rate=0.5)(req_emb)\n",
    "    req_emb = Dense(units=128, activation='tanh', name=f'{name}_embeddings')(req_emb)\n",
    "    req_model = Model(inputs=base_model.inputs, outputs=req_emb)\n",
    "\n",
    "    for layer in req_model.layers:\n",
    "        layer.trainable = (name in layer.name)\n",
    "\n",
    "    return req_model\n",
    "\n",
    "\n",
    "def build_siamese_model(req_model):\n",
    "    set_random_seeds()\n",
    "\n",
    "    input_anc = Input(shape=(*IMAGE_SIZE, 3))\n",
    "    input_pos = Input(shape=(*IMAGE_SIZE, 3))\n",
    "    input_neg = Input(shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "    output_anc = req_model(input_anc)\n",
    "    output_pos = req_model(input_pos)\n",
    "    output_neg = req_model(input_neg)\n",
    "\n",
    "    inputs = [input_anc, input_pos, input_neg]\n",
    "    outputs = Concatenate(axis=-1)([output_anc, output_pos, output_neg])\n",
    "\n",
    "    triplet_model = Model(inputs, outputs)\n",
    "    triplet_model.compile(optimizer='adam', loss=triplet_loss(alpha=ALPHA))\n",
    "\n",
    "    return triplet_model\n",
    "\n",
    "\n",
    "def train_embeddings(model, train_gen, valid_gen, name):\n",
    "    FILE_MODEL = FOLDER_MODELS + timestamp_model_name(prefix=f'{name}_')\n",
    "    \n",
    "    list_callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True),\n",
    "    ]\n",
    "    \n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "    mlflow.log_param(\"seed\", RANDOM_SEED)\n",
    "    mlflow.log_param(\"alpha\", ALPHA)\n",
    "    mlflow.set_tag(\"requirement\", name)\n",
    "    mlflow.keras.autolog()\n",
    "\n",
    "    hist = model.fit_generator(\n",
    "        train_gen, \n",
    "        steps_per_epoch=1000, \n",
    "        epochs=100, \n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=100,\n",
    "        callbacks=list_callbacks\n",
    "    )\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    return hist, FILE_MODEL\n",
    "\n",
    "\n",
    "def train_requirement_embeddings(base_model, pos_files, neg_files, datagen, name):\n",
    "    pos_train, pos_valid = train_test_split(pos_files, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "    neg_train, neg_valid = train_test_split(neg_files, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "    req_model = build_requirements_model(encoder, name)    \n",
    "    triplet_model = build_siamese_model(req_model)\n",
    "    \n",
    "    emb_dim = triplet_model.output_shape[-1] // 3\n",
    "    no_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "    train_gen = RandomTripletGenerator(pos_train, neg_train, IMAGE_SIZE, emb_dim, datagen=datagen)\n",
    "    valid_gen = RandomTripletGenerator(pos_valid, neg_valid, IMAGE_SIZE, emb_dim, datagen=no_datagen)\n",
    "    \n",
    "    hist, file_model = train_embeddings(triplet_model, train_gen, valid_gen, name)\n",
    "    plot.keras_hist(hist.history)\n",
    "\n",
    "    req_model.save(file_model)\n",
    "    return file_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "846\n",
      "Tensor(\"loss_8/concatenate_4_loss/loss_func/strided_slice:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"loss_8/concatenate_4_loss/loss_func/strided_slice_1:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"loss_8/concatenate_4_loss/loss_func/strided_slice_2:0\", shape=(?, 128), dtype=float32)\n",
      "Epoch 1/100\n",
      "  10/1000 [..............................] - ETA: 2:55 - loss: 1.7609"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b3423b71d5d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdatagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_requirement_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hat_cap'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-5d59bf2a315d>\u001b[0m in \u001b[0;36mtrain_requirement_embeddings\u001b[1;34m(base_model, pos_files, neg_files, datagen, name)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mvalid_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomTripletGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_datagen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriplet_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_hist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5d59bf2a315d>\u001b[0m in \u001b[0;36mtrain_embeddings\u001b[1;34m(model, train_gen, valid_gen, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     )\n\u001b[0;32m     56\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\mlflow\\keras.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0moriginal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgorilla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_original_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0munlogged_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'self'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'generator'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'validation_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_run_and_log_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlogged_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[0msettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgorilla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSettings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_hit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_hit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\mlflow\\keras.py\u001b[0m in \u001b[0;36m_run_and_log_function\u001b[1;34m(self, original, args, kwargs, unlogged_params, callback_arg_index)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0m_log_early_stop_callback_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0m_log_early_stop_callback_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FOLDER_REQ = 'hat_cap'\n",
    "\n",
    "pos_files = glob(f\"{FOLDER_IMAGES}/{FOLDER_REQ}/{FOLDER_POS}/*\")\n",
    "neg_files = glob(f\"{FOLDER_IMAGES}/{FOLDER_REQ}/{FOLDER_NEG}/*\")\n",
    "print(len(pos_files))\n",
    "print(len(neg_files))\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_file = train_requirement_embeddings(encoder, pos_files, neg_files, datagen, 'hat_cap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train, pos_valid = train_test_split(pos_files, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "neg_train, neg_valid = train_test_split(neg_files, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "no_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "train_gen = RandomTripletGenerator(pos_train, neg_train, IMAGE_SIZE, datagen=datagen)\n",
    "valid_gen = RandomTripletGenerator(pos_valid, neg_valid, IMAGE_SIZE, datagen=no_datagen)\n",
    "\n",
    "req_model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(anc, pos, neg), _ = valid_gen.__getitem__(None)\n",
    "\n",
    "emb_anc = req_model.predict(anc)\n",
    "emb_pos = req_model.predict(pos)\n",
    "emb_neg = req_model.predict(neg)\n",
    "\n",
    "pos_dist = np.sum((emb_anc - emb_pos) ** 2)\n",
    "neg_dist = np.sum((emb_anc - emb_neg) ** 2)\n",
    "loss = np.maximum(0.0, pos_dist - neg_dist + 0.2)\n",
    "\n",
    "print(pos_dist)\n",
    "print(neg_dist)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow((anc.squeeze()*255).astype(np.uint8)[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow((pos.squeeze()*255).astype(np.uint8)[:, :, ::-1])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow((neg.squeeze()*255).astype(np.uint8)[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_layer = encoder.get_layer(name='conv_5')\n",
    "req_layer = loaded_model.get_layer(name='conv_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "assert(np.allclose(K.eval(enc_layer.weights[0]), K.eval(req_layer.weights[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
