{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle as pkl\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Conv2D, GlobalAvgPool2D\n",
    "from keras.layers import Dense, Dropout, Concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import load, plot\n",
    "from local_config import FOLDER_IMAGES, FOLDER_MODELS\n",
    "from global_config import RANDOM_SEED, IMAGE_SIZE\n",
    "from custom_metrics import precision, recall, f1, specificity \n",
    "from custom_metrics import negative_predictive_value as npv \n",
    "from custom_metrics import matthews_correlation_coefficient as mcc\n",
    "from custom_metrics import equal_error_rate as eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_BASE_MODEL = '../../models/siamese_networks/autoencoder_2020_06_02-22_00_23.h5'\n",
    "\n",
    "VALID_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "ALPHA = 100.0\n",
    "EPOCHS = 100\n",
    "MLFLOW_EXPERIMENT_NAME = 'Siamese Networks'\n",
    "\n",
    "print(FILE_BASE_MODEL)\n",
    "print(FOLDER_IMAGES)\n",
    "print(FOLDER_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_model_name(prefix='model_', suffix='', format='%Y_%m_%d-%H_%M_%S', ext='.h5'):\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(format)\n",
    "    return f'{prefix}{timestamp}{suffix}{ext}'\n",
    "\n",
    "\n",
    "def set_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    rn.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.set_random_seed(RANDOM_SEED)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pos_and_neg_images(req_name):\n",
    "    pos_files = glob(f\"{FOLDER_IMAGES}/{req_name}/positives/*\")\n",
    "    neg_files = glob(f\"{FOLDER_IMAGES}/{req_name}/negatives/*\")\n",
    "    \n",
    "    x_pos = load.images_from_list_files(pos_files, IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    x_neg = load.images_from_list_files(neg_files, IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    x_pos_train, x_pos_valid = train_test_split(x_pos, test_size=VALID_SIZE, random_state=RANDOM_SEED)\n",
    "    x_neg_train, x_neg_valid = train_test_split(x_neg, test_size=VALID_SIZE, random_state=RANDOM_SEED)\n",
    "    \n",
    "    return x_pos_train, x_pos_valid, x_neg_train, x_neg_valid\n",
    "\n",
    "\n",
    "def setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid):\n",
    "    x_train = np.concatenate((x_pos_train, x_neg_train), axis=0)\n",
    "    y_train = np.array([1]*x_pos_train.shape[0] + [0]*x_neg_train.shape[0])\n",
    "    \n",
    "    x_valid = np.concatenate((x_pos_valid, x_neg_valid), axis=0)\n",
    "    y_valid = np.array([1]*x_pos_valid.shape[0] + [0]*x_neg_valid.shape[0])\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred) \n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    \n",
    "    accuracy_sk = accuracy_score(y_true, y_pred)\n",
    "    precision_sk = precision_score(y_true, y_pred)\n",
    "    recall_sk = recall_score(y_true, y_pred)\n",
    "    f_measure = f1_score(y_true, y_pred)\n",
    "    specificity_sk = tn / (tn + fp + 1e-7)\n",
    "    npv_sk = tn / (tn + fn + 1e-7)\n",
    "    \n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    mcc_sk = num / np.sqrt(den + 1e-7)\n",
    "    \n",
    "    print()\n",
    "    print('   Final Accuracy: {:=6.2f}%'.format(accuracy_sk * 100))\n",
    "    print('  Final Precision: {:=6.2f}%'.format(precision_sk * 100))\n",
    "    print('     Final Recall: {:=6.2f}%'.format(recall_sk * 100))\n",
    "    print('  Final F-measure: {:=6.2f}%'.format(f_measure * 100))\n",
    "    print('Final Specificity: {:=6.2f}%'.format(specificity_sk * 100))\n",
    "    print('        Final NPV: {:=6.2f}%'.format(npv_sk * 100))\n",
    "    print('        Final MCC: {:=6.2f}%'.format(mcc_sk * 100))\n",
    "    print()\n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTripletGenerator(Sequence):\n",
    "    \"\"\"Generate Random Triplets (A, P, N) for Siamese Networks on the fly\"\"\"\n",
    "\n",
    "    def __init__(self, pos_images, neg_images, emb_dim, batch_size=1, datagen=ImageDataGenerator(), random_seed=None):\n",
    "        self.pos_images = pos_images\n",
    "        self.neg_images = neg_images\n",
    "        self.emb_dim = emb_dim\n",
    "        self.batch_size = min(pos_images.shape[0], neg_images.shape[0])\n",
    "        self.datagen = datagen\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "    def __len__(self):\n",
    "        n_pos = self.pos_images.shape[0]\n",
    "        n_neg = self.neg_images.shape[0]\n",
    "        return min(n_pos, n_neg) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        anc_batch = self.datagen.flow(self.neg_images, batch_size=self.batch_size).next()\n",
    "        pos_batch = self.datagen.flow(self.pos_images, batch_size=self.batch_size).next()\n",
    "        neg_batch = self.datagen.flow(self.neg_images, batch_size=self.batch_size).next()\n",
    "        \n",
    "        x = [anc_batch, neg_batch, pos_batch]\n",
    "        y = np.zeros(shape=(self.batch_size, 3 * self.emb_dim))\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class DeterministicTripletGenerator(Sequence):\n",
    "    def __init__(self, triplet_gen, steps_per_epoch):\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.anc_gen = []\n",
    "        self.pos_gen = []\n",
    "        self.neg_gen = []\n",
    "        self.y_gen = []\n",
    "        \n",
    "        for i in range(steps_per_epoch):\n",
    "            (anc, neg, pos), y = triplet_gen.__getitem__(None)\n",
    "            self.anc_gen.append(anc)\n",
    "            self.neg_gen.append(neg)\n",
    "            self.pos_gen.append(pos)\n",
    "            self.y_gen.append(y)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        anc_batch = self.anc_gen[idx]\n",
    "        neg_batch = self.neg_gen[idx]\n",
    "        pos_batch = self.pos_gen[idx]\n",
    "        y_batch = self.y_gen[idx]\n",
    "        \n",
    "        return [anc_batch, neg_batch, pos_batch], y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBalancedDataGenerator(Sequence):\n",
    "    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n",
    "    def __init__(self, x, y, datagen=ImageDataGenerator(), batch_size=1):\n",
    "        self.datagen = datagen\n",
    "        self.batch_size = batch_size\n",
    "        self._shape = x.shape   \n",
    "        \n",
    "        self.datagen.fit(x)\n",
    "        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_batch, y_batch = self.gen.__next__()\n",
    "        x_batch = x_batch.reshape(-1, *self._shape[1:])\n",
    "        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()\n",
    "\n",
    "\n",
    "class DeterministicBalancedGenerator(Sequence):\n",
    "    def __init__(self, balanced_gen):\n",
    "        self.x_gen = []\n",
    "        self.y_gen = []\n",
    "        self.steps_per_epoch = balanced_gen.steps_per_epoch\n",
    "        \n",
    "        for i in range(balanced_gen.steps_per_epoch):\n",
    "            x, y = balanced_gen.__getitem__(None)\n",
    "            self.x_gen.append(x)\n",
    "            self.y_gen.append(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.steps_per_epoch\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_gen[idx], self.y_gen[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(alpha=0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "        anc -- the encodings for the anchor data\n",
    "        pos -- the encodings for the positive data\n",
    "        neg -- the encodings for the negative data\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    def loss_func(y_true, y_pred):\n",
    "        total_length = y_pred.shape.as_list()[-1]\n",
    "\n",
    "        anc = y_pred[:, 0:int(total_length * 1/3)]\n",
    "        pos = y_pred[:, int(total_length * 1/3):int(total_length * 2/3)]\n",
    "        neg = y_pred[:, int(total_length * 2/3):int(total_length * 3/3)]\n",
    "        \n",
    "        pos_dist = K.sum(K.square(anc - pos), axis=1)\n",
    "        neg_dist = K.sum(K.square(anc - neg), axis=1)\n",
    "\n",
    "        loss = K.maximum(pos_dist - neg_dist + alpha, 0.0)\n",
    "        return loss\n",
    " \n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(file_encoder):\n",
    "    autoencoder = load_model(file_encoder)\n",
    "    encoder = Model(inputs=autoencoder.inputs, outputs=autoencoder.get_layer(name='encoded').output)\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def build_shared_model(base_model, name):\n",
    "    set_random_seeds()\n",
    "    \n",
    "    req_emb = GlobalAvgPool2D()(base_model.output)\n",
    "    req_emb = Dropout(rate=0.5)(req_emb)\n",
    "    req_emb = Dense(units=128, activation='tanh', name=f'{name}_embeddings')(req_emb)\n",
    "    req_model = Model(inputs=base_model.inputs, outputs=req_emb)\n",
    "\n",
    "    for layer in req_model.layers:\n",
    "        layer.trainable = (name in layer.name)\n",
    "    return req_model\n",
    "\n",
    "\n",
    "def build_siamese_model(base_model):\n",
    "    set_random_seeds()\n",
    "\n",
    "    input_anc = Input(shape=(*IMAGE_SIZE, 3))\n",
    "    input_pos = Input(shape=(*IMAGE_SIZE, 3))\n",
    "    input_neg = Input(shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "    output_anc = base_model(input_anc)\n",
    "    output_pos = base_model(input_pos)\n",
    "    output_neg = base_model(input_neg)\n",
    "\n",
    "    inputs = [input_anc, input_pos, input_neg]\n",
    "    outputs = Concatenate(axis=-1)([output_anc, output_pos, output_neg])\n",
    "\n",
    "    triplet_model = Model(inputs, outputs)\n",
    "    triplet_model.compile(optimizer='adam', loss=triplet_loss(ALPHA))\n",
    "    return triplet_model\n",
    "\n",
    "\n",
    "def build_classification_model(base_model, name):\n",
    "    set_random_seeds()\n",
    "    \n",
    "    output_name = f'{name}_embeddings'\n",
    "    outputs = Dropout(rate=0.5)(base_model.get_layer(output_name).output)\n",
    "    outputs = Dense(units=1, activation='sigmoid', name=f'{name}')(outputs)\n",
    "    model = Model(inputs=base_model.inputs, outputs=outputs)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = name.endswith(layer.name)\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy', precision, recall, f1, specificity, npv, mcc, eer]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_siamese_model(model, train_gen, valid_gen):\n",
    "    list_callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True),\n",
    "    ]\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "        train_gen, \n",
    "        steps_per_epoch=100,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=valid_gen.steps_per_epoch,\n",
    "        callbacks=list_callbacks\n",
    "    )\n",
    "    \n",
    "    plot.keras_hist(hist.history)\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "def train_classification_model(model, train_gen, valid_gen, name):\n",
    "    FILE_MODEL = FOLDER_MODELS + '/' + timestamp_model_name(prefix=f'{name}_')\n",
    "    metric_to_monitor = 'val_matthews_correlation_coefficient'\n",
    "    \n",
    "    list_callbacks = [\n",
    "        EarlyStopping(monitor=metric_to_monitor, mode='max', patience=50, verbose=1, restore_best_weights=True),\n",
    "        ModelCheckpoint(FILE_MODEL, monitor=metric_to_monitor, mode='max', verbose=1, save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "    mlflow.log_param(\"seed\", RANDOM_SEED)\n",
    "    mlflow.log_param(\"alpha\", ALPHA)\n",
    "    mlflow.log_param(\"valid_size\", VALID_SIZE)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"file_model\", FILE_MODEL)\n",
    "    mlflow.set_tag(\"requirement\", name)\n",
    "    mlflow.keras.autolog()\n",
    "\n",
    "    hist = model.fit_generator(\n",
    "        train_gen, \n",
    "        steps_per_epoch=train_gen.steps_per_epoch,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=valid_gen.steps_per_epoch,\n",
    "        callbacks=list_callbacks\n",
    "    )\n",
    "    \n",
    "    plot.keras_hist(hist.history)\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    return FILE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_siamese_training(file_encoder, train_data, valid_data, train_gen, valid_gen, name):\n",
    "    model_encoder = load_encoder(file_encoder)\n",
    "    model_shared = build_shared_model(model_encoder, name)\n",
    "    model_siamese = build_siamese_model(model_shared)\n",
    "    \n",
    "    emb_dim = model_siamese.output_shape[-1] // 3\n",
    "    \n",
    "    x_pos_train, x_neg_train = train_data\n",
    "    x_pos_valid, x_neg_valid = valid_data\n",
    "    seed_triplet = RandomTripletGenerator(x_pos_valid, x_neg_valid, emb_dim, BATCH_SIZE, valid_gen, RANDOM_SEED)\n",
    "    train_gen_triplet = RandomTripletGenerator(x_pos_train, x_neg_train, emb_dim, BATCH_SIZE, train_gen)\n",
    "    valid_gen_triplet = DeterministicTripletGenerator(seed_triplet, steps_per_epoch=100)\n",
    "    \n",
    "    train_siamese_model(model_siamese, train_gen_triplet, valid_gen_triplet)\n",
    "\n",
    "    return model_shared\n",
    "    \n",
    "def run_classification_training(model_shared, train_data, valid_data, train_gen, valid_gen, name):\n",
    "    x_train, y_train = train_data\n",
    "    x_valid, y_valid = valid_data\n",
    "    \n",
    "    valid_bal = RandomBalancedDataGenerator(x_valid, y_valid, valid_gen, BATCH_SIZE)\n",
    "    train_gen_bal = RandomBalancedDataGenerator(x_train, y_train, train_gen, BATCH_SIZE)\n",
    "    valid_gen_bal = DeterministicBalancedGenerator(valid_bal)\n",
    "    \n",
    "    model_classification = build_classification_model(model_shared, name)\n",
    "    file_model = train_classification_model(model_classification, train_gen_bal, valid_gen_bal, name)\n",
    "\n",
    "    x_gen = valid_gen.flow(x_valid, batch_size=len(y_valid), shuffle=False).next()\n",
    "    y_pred = model_classification.predict(x_gen).flatten()\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "    print_metrics(y_valid, y_pred)\n",
    "    \n",
    "    return file_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "REQ_NAME = 'blurred'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Looking Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'looking_away'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~4. Ink Marked/Creased~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Unnatural Skin Tone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'unnatural_skin_tone'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Too Dark/Light "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'too_dark_light'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Washed Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'washed_out'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Pixelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'pixelation'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Hair Across Eyes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'hair_across_eyes'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Eyes Closed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'eyes_closed'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Varied Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'varied_background'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Roll/pitch/yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'roll_pitch_yaw'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Flash Reflection on Skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'flash_reflection_on_skin'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Red Eyes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'red_eyes'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Shadows Behind Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'shadows_behind_head'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Shadows Across Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'shadows_across_face'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Dark Tinted Lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'dark_tinted_lenses'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Flash Reflection on Lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'flash_reflection_on_lenses'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~19. Frames Too Heavy~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Frame Covering Eyes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'frame_covering_eyes'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. Hat/cap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'hat_cap'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *22. Veil Over Face*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'veil_over_face'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Mouth Open "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'mouth_open'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *24. Presence of Other Faces or Toys too Close to Face*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ_NAME = 'presence_of_other_faces_or_toys'\n",
    "\n",
    "x_pos_train, x_pos_valid, x_neg_train, x_neg_valid = load_pos_and_neg_images(REQ_NAME)\n",
    "x_train, y_train, x_valid, y_valid = setup_train_and_valid_sets(x_pos_train, x_pos_valid, x_neg_train, x_neg_valid)\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(x_valid.shape, x_valid.dtype)\n",
    "print(y_valid.shape, y_valid.dtype)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "valid_gen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "model_shared = run_siamese_training(\n",
    "    file_encoder=FILE_BASE_MODEL, \n",
    "    train_data=(x_pos_train, x_neg_train), \n",
    "    valid_data=(x_pos_valid, x_neg_valid), \n",
    "    train_gen=train_gen, \n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = run_classification_training(\n",
    "    model_shared=model_shared,\n",
    "    train_data=(x_train, y_train),\n",
    "    valid_data=(x_valid, y_valid),\n",
    "    train_gen=train_gen,\n",
    "    valid_gen=valid_gen,\n",
    "    name=REQ_NAME\n",
    ")\n",
    "\n",
    "list_model_files.append(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
