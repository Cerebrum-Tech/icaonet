{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('../src/')\n",
    "\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from os.path import join, exists\n",
    "from glob import glob\n",
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from icao_dataset import ICAODataset\n",
    "from utils import load\n",
    "from data_structures import Point, Eye, Rect\n",
    "from global_config import FOLDER_IMAGES, FOLDER_MRKS, FILE_DATASET, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data/cropped_faces/images/\n",
      "..\\data/cropped_faces/ground_truth/\n",
      "..\\data/cropped_faces_eyes/dataset_dlib.pkl\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_ROOT = \"..\"\n",
    "\n",
    "FOLDER_IMAGES = join(PATH_TO_ROOT, FOLDER_IMAGES)\n",
    "FOLDER_MRKS = join(PATH_TO_ROOT, FOLDER_MRKS)\n",
    "FILE_DATASET = join(PATH_TO_ROOT, FILE_DATASET)\n",
    "\n",
    "print(FOLDER_IMAGES)\n",
    "print(FOLDER_MRKS)\n",
    "print(FILE_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_pb(pb_file):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(open(pb_file, 'rb').read())\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FACE_DETECTOR = \"../vsproject/FVCSubmission/resources/models/face_detector.pb\"\n",
    "\n",
    "face_detector = load_graph_from_pb(MODEL_FACE_DETECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph(graph, inputs_list, input_tensor_names, output_tensor_names):\n",
    "    assert(len(inputs_list) == len(input_tensor_names))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        input_tensors = [graph.get_tensor_by_name(name) for name in input_tensor_names]\n",
    "        output_tensors = [graph.get_tensor_by_name(name) for name in output_tensor_names]\n",
    "        feed_dict = {tensor:value for tensor, value in zip(input_tensors, inputs_list)}\n",
    "        return sess.run(output_tensors, feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "def run_face_detector(bgr_image):\n",
    "    img = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.uint8)\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    inputs_list = [np.expand_dims(img, axis=0)]\n",
    "    input_tensor_names = ['import/image_tensor:0']\n",
    "    output_tensor_names = ['import/detection_boxes:0', 'import/detection_scores:0']\n",
    "    boxes, scores = run_graph(face_detector, inputs_list, input_tensor_names, output_tensor_names)\n",
    "\n",
    "    best_rect = boxes.squeeze()[scores.squeeze().argmax()]\n",
    "    best_rect = best_rect * [height, width, height, width]\n",
    "    best_rect = best_rect.astype(np.int)\n",
    "    y1, x1, y2, x2 = best_rect\n",
    "    return Rect.from_tl_br_points((x1, y1), (x2, y2))\n",
    "\n",
    "\n",
    "def update_eye_position(eye, offset):\n",
    "    return Eye.from_left_and_right_corners(\n",
    "        left_corner=eye.left_corner + offset,\n",
    "        right_corner=eye.right_corner + offset,\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_eye_position(eye, width, height):\n",
    "    p = Point(width, height)\n",
    "    return Eye.from_left_and_right_corners(\n",
    "        left_corner=eye.left_corner / p,\n",
    "        right_corner=eye.right_corner / p,\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocessing(bgr_image):\n",
    "    face_rect = run_face_detector(bgr_image)\n",
    "    w, h = face_rect.width, face_rect.height\n",
    "    \n",
    "    pad_rect = Rect(face_rect.x ,face_rect.y, w + int(w*1.5), h + int(h*1.5))\n",
    "    pad_rect.height= pad_rect.width = max(pad_rect.height, pad_rect.width)\n",
    "\n",
    "    center_pad = Point((pad_rect.x + pad_rect.width) // 2, (pad_rect.y + pad_rect.height) // 2)\n",
    "    center_face = Point((face_rect.x + face_rect.width) // 2, (face_rect.y + face_rect.height) // 2)\n",
    "    offset_center = Point(center_face.x - center_pad.x, center_face.y - center_pad.y)\n",
    "    pad_rect += offset_center\n",
    "\n",
    "    im_h, im_w = bgr_image.shape[:2]\n",
    "    tl_x, tl_y = pad_rect.tl()\n",
    "    br_x, br_y = pad_rect.br()\n",
    "    left = abs(min(0, pad_rect.x))\n",
    "    top = abs(min(0, pad_rect.y))\n",
    "    right = 0 if br_x < im_w else br_x - im_w\n",
    "    bottom = 0 if br_y < im_h else br_y - im_h\n",
    "\n",
    "    offset = Point(-tl_x, -tl_y)\n",
    "    \n",
    "    im_res = cv2.copyMakeBorder(bgr_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "    pad_rect.x += left\n",
    "    pad_rect.y += top\n",
    "    \n",
    "    l, t = pad_rect.tl()\n",
    "    r, b = pad_rect.br()\n",
    "    return im_res[t:b, l:r], offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New labels, wrong eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "5731 of 5731\n",
      "5731 of 5731\n"
     ]
    }
   ],
   "source": [
    "if exists(FILE_DATASET):\n",
    "    print(\"Dataset found. Loading...\")\n",
    "    dataset = pkl.load(open(FILE_DATASET, \"rb\"))\n",
    "else:\n",
    "    print(\"Generating dataset...\")\n",
    "    dataset = ICAODataset()\n",
    "    dataset.load(FOLDER_IMAGES, FOLDER_MRKS, output_size=IMAGE_SIZE)\n",
    "    pkl.dump(dataset, open(FILE_DATASET, \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old labels, right eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731 of 5731\n"
     ]
    }
   ],
   "source": [
    "list_mrks_fvc = [mrk.filepath.replace(\"cropped_faces\", \"all\") for mrk in dataset.mrks]\n",
    "mrks_fvc = load.mrk_files_from_list_files(list_mrks_fvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Ground-Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731 of 5731\r"
     ]
    }
   ],
   "source": [
    "N_FILES = len(mrks_fvc)\n",
    "\n",
    "for i, (file, mrk) in enumerate(zip(dataset.image_files, mrks_fvc)):\n",
    "    print(f\"{i + 1} of {N_FILES}\", end=\"\\r\")\n",
    "    stdout.flush()\n",
    "    \n",
    "    file = file.replace(\"cropped_faces\", \"all\")\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    _, offset = preprocessing(img)\n",
    "    dataset.mrks[i].left_eye = update_eye_position(mrk.left_eye, offset)\n",
    "    dataset.mrks[i].right_eye = update_eye_position(mrk.right_eye, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731 of 5731\r"
     ]
    }
   ],
   "source": [
    "dataset.save(\n",
    "    folder_images=join(PATH_TO_ROOT, \"data/cropped_faces_eyes/images\"), \n",
    "    folder_mrks=join(PATH_TO_ROOT, \"data/cropped_faces_eyes/ground_truth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(dataset, open(FILE_DATASET, \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data/cropped_faces_eyes/dataset_dlib.pkl\n"
     ]
    }
   ],
   "source": [
    "print(FILE_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Ground-Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found. Loading...\n"
     ]
    }
   ],
   "source": [
    "if exists(FILE_DATASET):\n",
    "    print(\"Dataset found. Loading...\")\n",
    "    dataset = pkl.load(open(FILE_DATASET, \"rb\"))\n",
    "else:\n",
    "    print(\"Generating dataset...\")\n",
    "    dataset = ICAODataset()\n",
    "    dataset.load(FOLDER_IMAGES, FOLDER_MRKS, output_size=IMAGE_SIZE)\n",
    "    pkl.dump(dataset, open(FILE_DATASET, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left corner: (0.6043613707165109, 0.470404984423676) right_corner: (0.6542056074766355, 0.470404984423676)\n",
      "left corner: (0.0009413728515833503, 0.0007327180442736386) right_corner: (0.0010190118496520803, 0.0007327180442736386)\n"
     ]
    }
   ],
   "source": [
    "N_FILES = len(dataset.image_files)\n",
    "\n",
    "for i, (file, _, mrk) in enumerate(dataset):\n",
    "    print(f\"{i + 1} of {N_FILES}\", end=\"\\r\")\n",
    "    stdout.flush()\n",
    "    \n",
    "    height, width, _ = cv2.imread(file, cv2.IMREAD_ANYCOLOR).shape\n",
    "#     dataset.mrks[i].left_eye = normalize_eye_position(mrk.left_eye, width, height)\n",
    "#     dataset.mrks[i].right_eye = normalize_eye_position(mrk.right_eye, width, height)\n",
    "    new_left_eye = normalize_eye_position(mrk.left_eye, width, height)\n",
    "    new_right_eye = normalize_eye_position(mrk.right_eye, width, height)\n",
    "    \n",
    "    print(mrk.left_eye)\n",
    "    print(new_left_eye)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 642)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NORMALIZED = FILE_DATASET.replace(\".pkl\", \"_normalized.pkl\")\n",
    "pkl.dump(dataset, open(FILE_NORMALIZED, \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FILE_NORMALIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
