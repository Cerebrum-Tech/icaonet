{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from src.mrk_file import MRKFile\n",
    "from src.iso_standard import PhotographicRequirements\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model, Input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TRAIN_DUMP = 'data/train_dump.pkl'\n",
    "FILE_TRAIN_BOTTLENECKS = 'data/train_bottlenecks.pkl'\n",
    "\n",
    "FILE_VAL_DUMP = 'data/val_dump.pkl'\n",
    "FILE_VAL_BOTTLENECKS = 'data/val_bottlenecks.pkl'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211 <class 'list'>\n",
      "(5211, 224, 224, 3) float32\n",
      "5211 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "train_image_files, x_train, train_mrks = pkl.load(open(FILE_TRAIN_DUMP, 'rb'))\n",
    "\n",
    "print(len(train_image_files), type(train_image_files))\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(len(train_mrks), type(train_mrks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 <class 'list'>\n",
      "(565, 224, 224, 3) float32\n",
      "565 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "val_image_files, x_val, val_mrks = pkl.load(open(FILE_VAL_DUMP, 'rb'))\n",
    "\n",
    "print(len(val_image_files), type(val_image_files))\n",
    "print(x_val.shape, x_val.dtype)\n",
    "print(len(val_mrks), type(val_mrks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Bottlenecks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211/5211 [==============================] - 8s 1ms/step\n",
      "565/565 [==============================] - 1s 1ms/step\n",
      "(5211, 7, 7, 1024) float32\n",
      "(565, 7, 7, 1024) float32\n"
     ]
    }
   ],
   "source": [
    "train_features = base_model.predict(x_train, batch_size=32, verbose=1)\n",
    "val_features = base_model.predict(x_val, batch_size=32, verbose=1)\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(val_features.shape, val_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 23) int8\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([mrk.photo_reqs.values() for mrk in train_mrks], dtype=np.int8)\n",
    "y_val = np.array([mrk.photo_reqs.values() for mrk in val_mrks], dtype=np.int8)\n",
    "\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(y_val.shape, y_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump((train_features, y_train), open(FILE_TRAIN_BOTTLENECKS, 'wb'), protocol=-1)\n",
    "pkl.dump((val_features, y_val), open(FILE_VAL_BOTTLENECKS, 'wb'), protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 7, 7, 1024) float32\n",
      "(5211, 23) int8\n",
      "(565, 7, 7, 1024) float32\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_features, y_train = pkl.load(open(FILE_TRAIN_BOTTLENECKS, 'rb'))\n",
    "val_features, y_val = pkl.load(open(FILE_VAL_BOTTLENECKS, 'rb'))\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "print(val_features.shape, val_features.dtype)\n",
    "print(y_val.shape, y_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 7, 7, 1024)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output_blurred (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_looking_away (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_ink_marked_creased (Dens (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_unnatural_skin_tone (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_too_dark_light (Dense)   (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_washed_out (Dense)       (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_pixelation (Dense)       (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_hair_across_eyes (Dense) (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_eyes_closed (Dense)      (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_varied_background (Dense (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_roll_pitch_yaw (Dense)   (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_flash_reflection_on_skin (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_red_eyes (Dense)         (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_shadows_behind_head (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_shadows_across_face (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_dark_tinted_lenses (Dens (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_flash_reflection_on_lens (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_frames_too_heavy (Dense) (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_frame_covering_eyes (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_hat_cap (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_veil_over_face (Dense)   (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_mouth_open (Dense)       (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "output_presence_of_other_faces_ (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 70,725\n",
      "Trainable params: 70,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=train_features.shape[1:], name='inputs')\n",
    "avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "r2 = Dense(units=3, activation='softmax', name='output_blurred')(avg_pool)\n",
    "r3 = Dense(units=3, activation='softmax', name='output_looking_away')(avg_pool)\n",
    "r4 = Dense(units=3, activation='softmax', name='output_ink_marked_creased')(avg_pool)\n",
    "r5 = Dense(units=3, activation='softmax', name='output_unnatural_skin_tone')(avg_pool)\n",
    "r6 = Dense(units=3, activation='softmax', name='output_too_dark_light')(avg_pool)\n",
    "r7 = Dense(units=3, activation='softmax', name='output_washed_out')(avg_pool)\n",
    "r8 = Dense(units=3, activation='softmax', name='output_pixelation')(avg_pool)\n",
    "r9 = Dense(units=3, activation='softmax', name='output_hair_across_eyes')(avg_pool)\n",
    "r10 = Dense(units=3, activation='softmax', name='output_eyes_closed')(avg_pool)\n",
    "r11 = Dense(units=3, activation='softmax', name='output_varied_background')(avg_pool)\n",
    "r12 = Dense(units=3, activation='softmax', name='output_roll_pitch_yaw')(avg_pool)\n",
    "r13 = Dense(units=3, activation='softmax', name='output_flash_reflection_on_skin')(avg_pool)\n",
    "r14 = Dense(units=3, activation='softmax', name='output_red_eyes')(avg_pool)\n",
    "r15 = Dense(units=3, activation='softmax', name='output_shadows_behind_head')(avg_pool)\n",
    "r16 = Dense(units=3, activation='softmax', name='output_shadows_across_face')(avg_pool)\n",
    "r17 = Dense(units=3, activation='softmax', name='output_dark_tinted_lenses')(avg_pool)\n",
    "r18 = Dense(units=3, activation='softmax', name='output_flash_reflection_on_lenses')(avg_pool)\n",
    "r19 = Dense(units=3, activation='softmax', name='output_frames_too_heavy')(avg_pool)\n",
    "r20 = Dense(units=3, activation='softmax', name='output_frame_covering_eyes')(avg_pool)\n",
    "r21 = Dense(units=3, activation='softmax', name='output_hat_cap')(avg_pool)\n",
    "r22 = Dense(units=3, activation='softmax', name='output_veil_over_face')(avg_pool)\n",
    "r23 = Dense(units=3, activation='softmax', name='output_mouth_open')(avg_pool)\n",
    "r24 = Dense(units=3, activation='softmax', name='output_presence_of_other_faces_or_toys')(avg_pool)\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=[r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15, r16, r17, r18, r19, r20, r21, r22, r23, r24], \n",
    "              name='icaonet')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5211/5211 [==============================] - 6s 1ms/step - loss: nan - output_blurred_loss: nan - output_looking_away_loss: nan - output_ink_marked_creased_loss: nan - output_unnatural_skin_tone_loss: nan - output_too_dark_light_loss: nan - output_washed_out_loss: nan - output_pixelation_loss: nan - output_hair_across_eyes_loss: nan - output_eyes_closed_loss: nan - output_varied_background_loss: nan - output_roll_pitch_yaw_loss: nan - output_flash_reflection_on_skin_loss: nan - output_red_eyes_loss: nan - output_shadows_behind_head_loss: nan - output_shadows_across_face_loss: nan - output_dark_tinted_lenses_loss: 0.2926 - output_flash_reflection_on_lenses_loss: nan - output_frames_too_heavy_loss: nan - output_frame_covering_eyes_loss: nan - output_hat_cap_loss: nan - output_veil_over_face_loss: 0.1697 - output_mouth_open_loss: nan - output_presence_of_other_faces_or_toys_loss: nan - output_blurred_acc: 0.1418 - output_looking_away_acc: 0.1128 - output_ink_marked_creased_acc: 0.0081 - output_unnatural_skin_tone_acc: 0.0399 - output_too_dark_light_acc: 0.0664 - output_washed_out_acc: 0.6682 - output_pixelation_acc: 0.3197 - output_hair_across_eyes_acc: 0.1297 - output_eyes_closed_acc: 0.0902 - output_varied_background_acc: 0.4258 - output_roll_pitch_yaw_acc: 0.2727 - output_flash_reflection_on_skin_acc: 0.2092 - output_red_eyes_acc: 0.0038 - output_shadows_behind_head_acc: 0.1019 - output_shadows_across_face_acc: 0.1929 - output_dark_tinted_lenses_acc: 0.8923 - output_flash_reflection_on_lenses_acc: 0.2988 - output_frames_too_heavy_acc: 0.0223 - output_frame_covering_eyes_acc: 0.1054 - output_hat_cap_acc: 0.3149 - output_veil_over_face_acc: 0.9490 - output_mouth_open_acc: 0.1671 - output_presence_of_other_faces_or_toys_acc: 0.3381: 0s - loss: nan - output_blurred_loss: nan - output_looking_away_loss: nan - output_ink_marked_creased_loss: nan - output_unnatural_skin_tone_loss: nan - output_too_dark_light_loss: nan - output_washed_out_loss: nan - output_pixelation_loss: nan - output_hair_across_eyes_loss: nan - output_eyes_closed_loss: nan - output_varied_background_loss: nan - output_roll_pitch_yaw_loss: nan - output_flash_reflection_on_skin_loss: nan - output_red_eyes_loss: nan - output_shadows_behind_head_loss: nan - output_shadows_across_face_loss: nan - output_dark_tinted_lenses_loss: 0.2933 - output_flash_reflection_on_lenses_loss: nan - output_frames_too_heavy_loss: nan - output_frame_covering_eyes_loss: nan - output_hat_cap_loss: nan - output_veil_over_face_loss: 0.1703 - output_mouth_open_loss: nan - output_presence_of_other_faces_or_toys_loss: nan - output_blurred_acc: 0.1420 - output_looking_away_acc: 0.1130 - output_ink_marked_creased_acc: 0.0081 - output_unnatural_skin_tone_acc: 0.0395 - output_too_dark_light_acc: 0.0667 - output_washed_out_acc: 0.6717 - output_pixelation_acc: 0.3212 - output_hair_across_eyes_acc: 0.1300 - output_eyes_closed_acc: 0.0903 - output_varied_background_acc: 0.4269 - output_roll_pitch_yaw_acc: 0.2726 - output_flash_reflection_on_skin_acc: 0.2091 - output_red_eyes_acc: 0.0039 - output_shadows_behind_head_acc: 0.1020 - output_shadows_across_face_acc: 0.1929 - output_dark_tinted_lenses_acc: 0.8920 - output_flash_reflection_on_lenses_acc: 0.2992 - output_frames_too_heavy_acc: 0.0224 - output_frame_covering_eyes_acc: 0.1053 - output_hat_cap_acc: 0.3158 - output_veil_over_face_acc: 0.9487 - output_mouth_open_acc: 0.1672 - output_presence_of_other_faces_or_toys_acc: 0.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f30fd4e48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, np.hsplit(y_train, range(1, y_train.shape[1])), batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
