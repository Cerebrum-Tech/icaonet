{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from math import ceil\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.mrk_file import MRKFile\n",
    "from src.iso_standard import PhotographicRequirements\n",
    "from src.utils.plot import plot_confusion_matrix\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TRAIN_DUMP = 'data/train_dump.pkl'\n",
    "FILE_TRAIN_BOTTLENECKS = 'data/train_bottlenecks.pkl'\n",
    "\n",
    "FILE_VAL_DUMP = 'data/val_dump.pkl'\n",
    "FILE_VAL_BOTTLENECKS = 'data/val_bottlenecks.pkl'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = ['blurred', \n",
    "                'looking_away', \n",
    "                'ink_marked_creased', \n",
    "                'unnatural_skin_tone', \n",
    "                'too_dark_light', \n",
    "                'washed_out', \n",
    "                'pixelation', \n",
    "                'hair_across_eyes', \n",
    "                'eyes_closed', \n",
    "                'varied_background', \n",
    "                'roll_pitch_yaw', \n",
    "                'flash_reflection_on_skin', \n",
    "                'red_eyes', \n",
    "                'shadows_behind_head', \n",
    "                'shadows_across_face', \n",
    "                'dark_tinted_lenses', \n",
    "                'flash_reflection_on_lenses', \n",
    "                'frames_too_heavy', \n",
    "                'frame_covering_eyes', \n",
    "                'hat_cap', \n",
    "                'veil_over_face', \n",
    "                'mouth_open', \n",
    "                'presence_of_other_faces_or_toys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_to_dataframe(history, epoch=-1):\n",
    "    loss_train = np.array([history[name + '_loss'][epoch] for name in output_names])\n",
    "    loss_val = np.array([history['val_' + name + '_loss'][epoch] for name in output_names])\n",
    "    acc_train = np.array([history[name + '_acc'][epoch] for name in output_names]) * 100\n",
    "    acc_val = np.array([history['val_' + name + '_acc'][epoch] for name in output_names]) * 100\n",
    "\n",
    "    data = np.concatenate(([loss_train], [loss_val], [acc_train], [acc_val]), axis=0).T\n",
    "    return pd.DataFrame(data, columns=['loss_train', 'loss_val', 'acc_train', 'acc_val'], index=output_names)\n",
    "\n",
    "def load_proportions(file_txt):\n",
    "    prop_values = np.loadtxt(file_txt)\n",
    "    return pd.DataFrame(prop_values, index=output_names).T\n",
    "\n",
    "def plot_graph(subplot, train, val, title):\n",
    "    plt.subplot(*subplot)\n",
    "    plt.plot(train, label='train')\n",
    "    plt.plot(val, label='val')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "def save_history(history, output_file):\n",
    "    n_epochs = len(history['loss'])\n",
    "    n_graphs = len(output_names) * 2\n",
    "    n_cols = 2\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "\n",
    "    df_train_props = load_proportions('data/train_max_proportions.txt')\n",
    "    df_val_props = load_proportions('data/val_max_proportions.txt')\n",
    "    \n",
    "    plt.figure(figsize=(16, 100))\n",
    "    for i, name in zip(range(1, n_graphs, 2), output_names):\n",
    "        train_loss = history[name + '_loss']\n",
    "        train_acc = history[name + '_acc']\n",
    "        val_loss = history['val_' + name + '_loss']\n",
    "        val_acc = history['val_' + name + '_acc']\n",
    "\n",
    "        plot_graph((n_rows, n_cols, i), train_loss, val_loss, '{} ({})'.format(name, 'loss'))\n",
    "        plot_graph((n_rows, n_cols, i + 1), train_acc, val_acc, '{} ({})'.format(name, 'acc'))\n",
    "        plt.hlines(df_train_props[name], 0, n_epochs, linestyle=':', color='blue')\n",
    "        plt.hlines(df_val_props[name], 0, n_epochs, linestyle=':', color='orange')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "def save_heatmaps(y_trues, y_preds, output_file, figsize=(20, 20)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    n_graphs = len(output_names)\n",
    "    n_cols = 5\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "    labels = np.unique(y_trues)\n",
    "\n",
    "    for i, name, y_true, y_pred in zip(range(1, n_graphs + 1), output_names, y_trues, y_preds):\n",
    "        y_pred = np.argmax(y_pred, axis=-1)\n",
    "        conf_matrix = confusion_matrix(y_true.ravel(), y_pred, labels=labels)\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        plot_confusion_matrix(conf_matrix, \n",
    "                              target_names=['D', 'NC', 'C'], \n",
    "                              title=name, \n",
    "                              normalize=True)\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211 <class 'list'>\n",
      "(5211, 224, 224, 3) float32\n",
      "5211 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "train_image_files, x_train, train_mrks = pkl.load(open(FILE_TRAIN_DUMP, 'rb'))\n",
    "\n",
    "print(len(train_image_files), type(train_image_files))\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(len(train_mrks), type(train_mrks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 <class 'list'>\n",
      "(565, 224, 224, 3) float32\n",
      "565 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "val_image_files, x_val, val_mrks = pkl.load(open(FILE_VAL_DUMP, 'rb'))\n",
    "\n",
    "print(len(val_image_files), type(val_image_files))\n",
    "print(x_val.shape, x_val.dtype)\n",
    "print(len(val_mrks), type(val_mrks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Bottlenecks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211/5211 [==============================] - 7s 1ms/step\n",
      "565/565 [==============================] - 1s 1ms/step\n",
      "(5211, 7, 7, 1024) float32\n",
      "(565, 7, 7, 1024) float32\n"
     ]
    }
   ],
   "source": [
    "train_features = base_model.predict(x_train, batch_size=32, verbose=1)\n",
    "val_features = base_model.predict(x_val, batch_size=32, verbose=1)\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(val_features.shape, val_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 23) int8\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_values = np.array([mrk.photo_reqs.values() for mrk in train_mrks], dtype=np.int8)\n",
    "val_values = np.array([mrk.photo_reqs.values() for mrk in val_mrks], dtype=np.int8)\n",
    "\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump((train_features, train_values), open(FILE_TRAIN_BOTTLENECKS, 'wb'), protocol=-1)\n",
    "pkl.dump((val_features, val_values), open(FILE_VAL_BOTTLENECKS, 'wb'), protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 7, 7, 1024) float32\n",
      "(5211, 23) int8\n",
      "(565, 7, 7, 1024) float32\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_features, train_values = pkl.load(open(FILE_TRAIN_BOTTLENECKS, 'rb'))\n",
    "val_features, val_values = pkl.load(open(FILE_VAL_BOTTLENECKS, 'rb'))\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_features.shape, val_features.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode reqs values from [-1, 0, 1] => [0, 1, 2]\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_values.ravel())\n",
    "\n",
    "y_train = enc.transform(train_values.ravel()).reshape(train_values.shape)\n",
    "y_val = enc.transform(val_values.ravel()).reshape(val_values.shape)\n",
    "\n",
    "assert(y_train.shape == train_values.shape)\n",
    "assert(y_val.shape == val_values.shape)\n",
    "assert(np.all(y_train == train_values + 1))\n",
    "assert(np.all(y_val == val_values + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 7, 7, 1024)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blurred (Dense)                 (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "looking_away (Dense)            (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ink_marked_creased (Dense)      (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unnatural_skin_tone (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "too_dark_light (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "washed_out (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "pixelation (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "hair_across_eyes (Dense)        (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "eyes_closed (Dense)             (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "varied_background (Dense)       (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "roll_pitch_yaw (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_skin (Dense (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "red_eyes (Dense)                (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "shadows_behind_head (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "shadows_across_face (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dark_tinted_lenses (Dense)      (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_lenses (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "frames_too_heavy (Dense)        (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "frame_covering_eyes (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "hat_cap (Dense)                 (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "veil_over_face (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mouth_open (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "presence_of_other_faces_or_toys (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 70,725\n",
      "Trainable params: 70,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=train_features.shape[1:], name='inputs')\n",
    "avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "r2 = Dense(units=3, activation='softmax', name=output_names[0])(avg_pool)\n",
    "r3 = Dense(units=3, activation='softmax', name=output_names[1])(avg_pool)\n",
    "r4 = Dense(units=3, activation='softmax', name=output_names[2])(avg_pool)\n",
    "r5 = Dense(units=3, activation='softmax', name=output_names[3])(avg_pool)\n",
    "r6 = Dense(units=3, activation='softmax', name=output_names[4])(avg_pool)\n",
    "r7 = Dense(units=3, activation='softmax', name=output_names[5])(avg_pool)\n",
    "r8 = Dense(units=3, activation='softmax', name=output_names[6])(avg_pool)\n",
    "r9 = Dense(units=3, activation='softmax', name=output_names[7])(avg_pool)\n",
    "r10 = Dense(units=3, activation='softmax', name=output_names[8])(avg_pool)\n",
    "r11 = Dense(units=3, activation='softmax', name=output_names[9])(avg_pool)\n",
    "r12 = Dense(units=3, activation='softmax', name=output_names[10])(avg_pool)\n",
    "r13 = Dense(units=3, activation='softmax', name=output_names[11])(avg_pool)\n",
    "r14 = Dense(units=3, activation='softmax', name=output_names[12])(avg_pool)\n",
    "r15 = Dense(units=3, activation='softmax', name=output_names[13])(avg_pool)\n",
    "r16 = Dense(units=3, activation='softmax', name=output_names[14])(avg_pool)\n",
    "r17 = Dense(units=3, activation='softmax', name=output_names[15])(avg_pool)\n",
    "r18 = Dense(units=3, activation='softmax', name=output_names[16])(avg_pool)\n",
    "r19 = Dense(units=3, activation='softmax', name=output_names[17])(avg_pool)\n",
    "r20 = Dense(units=3, activation='softmax', name=output_names[18])(avg_pool)\n",
    "r21 = Dense(units=3, activation='softmax', name=output_names[19])(avg_pool)\n",
    "r22 = Dense(units=3, activation='softmax', name=output_names[20])(avg_pool)\n",
    "r23 = Dense(units=3, activation='softmax', name=output_names[21])(avg_pool)\n",
    "r24 = Dense(units=3, activation='softmax', name=output_names[22])(avg_pool)\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=[r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15, r16, r17, r18, r19, r20, r21, r22, r23, r24], \n",
    "              name='icaonet')\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5211 samples, validate on 565 samples\n",
      "Epoch 1/3\n",
      "5211/5211 [==============================] - 7s 1ms/step - loss: 9.0526 - blurred_loss: 0.4771 - looking_away_loss: 0.7751 - ink_marked_creased_loss: 0.1632 - unnatural_skin_tone_loss: 0.2981 - too_dark_light_loss: 0.2395 - washed_out_loss: 0.0399 - pixelation_loss: 0.2633 - hair_across_eyes_loss: 0.3360 - eyes_closed_loss: 0.6448 - varied_background_loss: 0.3193 - roll_pitch_yaw_loss: 0.6517 - flash_reflection_on_skin_loss: 0.5194 - red_eyes_loss: 0.5116 - shadows_behind_head_loss: 0.6837 - shadows_across_face_loss: 0.3872 - dark_tinted_lenses_loss: 0.3740 - flash_reflection_on_lenses_loss: 0.3994 - frames_too_heavy_loss: 0.3143 - frame_covering_eyes_loss: 0.4970 - hat_cap_loss: 0.4121 - veil_over_face_loss: 0.1435 - mouth_open_loss: 0.5481 - presence_of_other_faces_or_toys_loss: 0.0544 - blurred_acc: 0.8355 - looking_away_acc: 0.6891 - ink_marked_creased_acc: 0.9394 - unnatural_skin_tone_acc: 0.9221 - too_dark_light_acc: 0.9371 - washed_out_acc: 0.9837 - pixelation_acc: 0.9278 - hair_across_eyes_acc: 0.8789 - eyes_closed_acc: 0.7922 - varied_background_acc: 0.8793 - roll_pitch_yaw_acc: 0.7120 - flash_reflection_on_skin_acc: 0.8258 - red_eyes_acc: 0.8098 - shadows_behind_head_acc: 0.7478 - shadows_across_face_acc: 0.8553 - dark_tinted_lenses_acc: 0.8684 - flash_reflection_on_lenses_acc: 0.8423 - frames_too_heavy_acc: 0.9119 - frame_covering_eyes_acc: 0.8259 - hat_cap_acc: 0.8490 - veil_over_face_acc: 0.9551 - mouth_open_acc: 0.7832 - presence_of_other_faces_or_toys_acc: 0.9881 - val_loss: 13.5601 - val_blurred_loss: 0.2847 - val_looking_away_loss: 0.7044 - val_ink_marked_creased_loss: 0.0667 - val_unnatural_skin_tone_loss: 1.2870 - val_too_dark_light_loss: 0.5587 - val_washed_out_loss: 0.7059 - val_pixelation_loss: 0.2098 - val_hair_across_eyes_loss: 0.5021 - val_eyes_closed_loss: 0.5394 - val_varied_background_loss: 1.3397 - val_roll_pitch_yaw_loss: 0.9878 - val_flash_reflection_on_skin_loss: 1.0680 - val_red_eyes_loss: 0.8018 - val_shadows_behind_head_loss: 0.1929 - val_shadows_across_face_loss: 1.6160 - val_dark_tinted_lenses_loss: 0.1531 - val_flash_reflection_on_lenses_loss: 0.4665 - val_frames_too_heavy_loss: 0.1204 - val_frame_covering_eyes_loss: 0.5509 - val_hat_cap_loss: 0.1891 - val_veil_over_face_loss: 0.1145 - val_mouth_open_loss: 0.9567 - val_presence_of_other_faces_or_toys_loss: 0.1439 - val_blurred_acc: 0.8796 - val_looking_away_acc: 0.7770 - val_ink_marked_creased_acc: 0.9823 - val_unnatural_skin_tone_acc: 0.7097 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8637 - val_varied_background_acc: 0.8088 - val_roll_pitch_yaw_acc: 0.8248 - val_flash_reflection_on_skin_acc: 0.7681 - val_red_eyes_acc: 0.7540 - val_shadows_behind_head_acc: 0.9469 - val_shadows_across_face_acc: 0.6796 - val_dark_tinted_lenses_acc: 0.9646 - val_flash_reflection_on_lenses_acc: 0.8726 - val_frames_too_heavy_acc: 0.9628 - val_frame_covering_eyes_acc: 0.8619 - val_hat_cap_acc: 0.9416 - val_veil_over_face_acc: 0.9628 - val_mouth_open_acc: 0.6637 - val_presence_of_other_faces_or_toys_acc: 0.9823\n",
      "Epoch 2/3\n",
      "5211/5211 [==============================] - 4s 712us/step - loss: 6.7429 - blurred_loss: 0.3786 - looking_away_loss: 0.6437 - ink_marked_creased_loss: 0.1006 - unnatural_skin_tone_loss: 0.1985 - too_dark_light_loss: 0.1887 - washed_out_loss: 0.0086 - pixelation_loss: 0.2293 - hair_across_eyes_loss: 0.2377 - eyes_closed_loss: 0.4786 - varied_background_loss: 0.2249 - roll_pitch_yaw_loss: 0.5668 - flash_reflection_on_skin_loss: 0.3443 - red_eyes_loss: 0.3638 - shadows_behind_head_loss: 0.5393 - shadows_across_face_loss: 0.3052 - dark_tinted_lenses_loss: 0.2013 - flash_reflection_on_lenses_loss: 0.3085 - frames_too_heavy_loss: 0.2164 - frame_covering_eyes_loss: 0.3967 - hat_cap_loss: 0.2440 - veil_over_face_loss: 0.0775 - mouth_open_loss: 0.4674 - presence_of_other_faces_or_toys_loss: 0.0223 - blurred_acc: 0.8659 - looking_away_acc: 0.7404 - ink_marked_creased_acc: 0.9547 - unnatural_skin_tone_acc: 0.9390 - too_dark_light_acc: 0.9443 - washed_out_acc: 0.9990 - pixelation_acc: 0.9300 - hair_across_eyes_acc: 0.9065 - eyes_closed_acc: 0.8426 - varied_background_acc: 0.9192 - roll_pitch_yaw_acc: 0.7561 - flash_reflection_on_skin_acc: 0.8864 - red_eyes_acc: 0.8649 - shadows_behind_head_acc: 0.7881 - shadows_across_face_acc: 0.8929 - dark_tinted_lenses_acc: 0.9257 - flash_reflection_on_lenses_acc: 0.8785 - frames_too_heavy_acc: 0.9372 - frame_covering_eyes_acc: 0.8507 - hat_cap_acc: 0.9096 - veil_over_face_acc: 0.9795 - mouth_open_acc: 0.8092 - presence_of_other_faces_or_toys_acc: 0.9967 - val_loss: 13.3832 - val_blurred_loss: 0.3247 - val_looking_away_loss: 0.6841 - val_ink_marked_creased_loss: 0.1225 - val_unnatural_skin_tone_loss: 1.5698 - val_too_dark_light_loss: 0.4720 - val_washed_out_loss: 0.6314 - val_pixelation_loss: 0.2080 - val_hair_across_eyes_loss: 0.5886 - val_eyes_closed_loss: 0.5238 - val_varied_background_loss: 1.1743 - val_roll_pitch_yaw_loss: 0.8917 - val_flash_reflection_on_skin_loss: 1.1608 - val_red_eyes_loss: 0.8261 - val_shadows_behind_head_loss: 0.1887 - val_shadows_across_face_loss: 1.5544 - val_dark_tinted_lenses_loss: 0.1039 - val_flash_reflection_on_lenses_loss: 0.4378 - val_frames_too_heavy_loss: 0.0801 - val_frame_covering_eyes_loss: 0.5547 - val_hat_cap_loss: 0.1646 - val_veil_over_face_loss: 0.0776 - val_mouth_open_loss: 0.9177 - val_presence_of_other_faces_or_toys_loss: 0.1260 - val_blurred_acc: 0.8690 - val_looking_away_acc: 0.7947 - val_ink_marked_creased_acc: 0.9310 - val_unnatural_skin_tone_acc: 0.7097 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8673 - val_varied_background_acc: 0.8088 - val_roll_pitch_yaw_acc: 0.8319 - val_flash_reflection_on_skin_acc: 0.7805 - val_red_eyes_acc: 0.7363 - val_shadows_behind_head_acc: 0.9770 - val_shadows_across_face_acc: 0.6920 - val_dark_tinted_lenses_acc: 0.9664 - val_flash_reflection_on_lenses_acc: 0.8832 - val_frames_too_heavy_acc: 0.9664 - val_frame_covering_eyes_acc: 0.8673 - val_hat_cap_acc: 0.9451 - val_veil_over_face_acc: 0.9894 - val_mouth_open_acc: 0.6814 - val_presence_of_other_faces_or_toys_acc: 0.9823\n",
      "Epoch 3/3\n",
      "5211/5211 [==============================] - 4s 721us/step - loss: 6.2360 - blurred_loss: 0.3582 - looking_away_loss: 0.6178 - ink_marked_creased_loss: 0.0950 - unnatural_skin_tone_loss: 0.1800 - too_dark_light_loss: 0.1642 - washed_out_loss: 0.0075 - pixelation_loss: 0.2165 - hair_across_eyes_loss: 0.2127 - eyes_closed_loss: 0.4419 - varied_background_loss: 0.1987 - roll_pitch_yaw_loss: 0.5391 - flash_reflection_on_skin_loss: 0.3181 - red_eyes_loss: 0.3396 - shadows_behind_head_loss: 0.4987 - shadows_across_face_loss: 0.2786 - dark_tinted_lenses_loss: 0.1719 - flash_reflection_on_lenses_loss: 0.2988 - frames_too_heavy_loss: 0.1935 - frame_covering_eyes_loss: 0.3667 - hat_cap_loss: 0.2077 - veil_over_face_loss: 0.0668 - mouth_open_loss: 0.4435 - presence_of_other_faces_or_toys_loss: 0.0204 - blurred_acc: 0.8705 - looking_away_acc: 0.7571 - ink_marked_creased_acc: 0.9580 - unnatural_skin_tone_acc: 0.9392 - too_dark_light_acc: 0.9499 - washed_out_acc: 0.9990 - pixelation_acc: 0.9305 - hair_across_eyes_acc: 0.9167 - eyes_closed_acc: 0.8511 - varied_background_acc: 0.9271 - roll_pitch_yaw_acc: 0.7693 - flash_reflection_on_skin_acc: 0.8906 - red_eyes_acc: 0.8774 - shadows_behind_head_acc: 0.8027 - shadows_across_face_acc: 0.9014 - dark_tinted_lenses_acc: 0.9396 - flash_reflection_on_lenses_acc: 0.8801 - frames_too_heavy_acc: 0.9415 - frame_covering_eyes_acc: 0.8632 - hat_cap_acc: 0.9255 - veil_over_face_acc: 0.9810 - mouth_open_acc: 0.8160 - presence_of_other_faces_or_toys_acc: 0.9967 - val_loss: 13.1310 - val_blurred_loss: 0.3186 - val_looking_away_loss: 0.7277 - val_ink_marked_creased_loss: 0.1404 - val_unnatural_skin_tone_loss: 1.4691 - val_too_dark_light_loss: 0.4669 - val_washed_out_loss: 0.5914 - val_pixelation_loss: 0.1988 - val_hair_across_eyes_loss: 0.6138 - val_eyes_closed_loss: 0.5474 - val_varied_background_loss: 1.1645 - val_roll_pitch_yaw_loss: 0.8930 - val_flash_reflection_on_skin_loss: 1.0433 - val_red_eyes_loss: 0.8356 - val_shadows_behind_head_loss: 0.1455 - val_shadows_across_face_loss: 1.4990 - val_dark_tinted_lenses_loss: 0.0975 - val_flash_reflection_on_lenses_loss: 0.4101 - val_frames_too_heavy_loss: 0.1015 - val_frame_covering_eyes_loss: 0.5217 - val_hat_cap_loss: 0.1587 - val_veil_over_face_loss: 0.0630 - val_mouth_open_loss: 1.0079 - val_presence_of_other_faces_or_toys_loss: 0.1158 - val_blurred_acc: 0.8673 - val_looking_away_acc: 0.7982 - val_ink_marked_creased_acc: 0.9115 - val_unnatural_skin_tone_acc: 0.7274 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8708 - val_varied_background_acc: 0.8088 - val_roll_pitch_yaw_acc: 0.8319 - val_flash_reflection_on_skin_acc: 0.7434 - val_red_eyes_acc: 0.7558 - val_shadows_behind_head_acc: 0.9646 - val_shadows_across_face_acc: 0.6814 - val_dark_tinted_lenses_acc: 0.9876 - val_flash_reflection_on_lenses_acc: 0.9097 - val_frames_too_heavy_acc: 0.9575 - val_frame_covering_eyes_acc: 0.8761 - val_hat_cap_acc: 0.9540 - val_veil_over_face_acc: 0.9929 - val_mouth_open_acc: 0.6850 - val_presence_of_other_faces_or_toys_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blurred</th>\n",
       "      <td>0.477066</td>\n",
       "      <td>0.284701</td>\n",
       "      <td>83.554020</td>\n",
       "      <td>87.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking_away</th>\n",
       "      <td>0.775122</td>\n",
       "      <td>0.704371</td>\n",
       "      <td>68.911917</td>\n",
       "      <td>77.699115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ink_marked_creased</th>\n",
       "      <td>0.163186</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>93.935905</td>\n",
       "      <td>98.230088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unnatural_skin_tone</th>\n",
       "      <td>0.298098</td>\n",
       "      <td>1.286963</td>\n",
       "      <td>92.208789</td>\n",
       "      <td>70.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too_dark_light</th>\n",
       "      <td>0.239507</td>\n",
       "      <td>0.558732</td>\n",
       "      <td>93.705623</td>\n",
       "      <td>87.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washed_out</th>\n",
       "      <td>0.039938</td>\n",
       "      <td>0.705906</td>\n",
       "      <td>98.368835</td>\n",
       "      <td>93.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixelation</th>\n",
       "      <td>0.263314</td>\n",
       "      <td>0.209834</td>\n",
       "      <td>92.784494</td>\n",
       "      <td>94.867257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair_across_eyes</th>\n",
       "      <td>0.335975</td>\n",
       "      <td>0.502080</td>\n",
       "      <td>87.891000</td>\n",
       "      <td>91.504425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes_closed</th>\n",
       "      <td>0.644777</td>\n",
       "      <td>0.539429</td>\n",
       "      <td>79.217041</td>\n",
       "      <td>86.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varied_background</th>\n",
       "      <td>0.319334</td>\n",
       "      <td>1.339677</td>\n",
       "      <td>87.929380</td>\n",
       "      <td>80.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll_pitch_yaw</th>\n",
       "      <td>0.651660</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>71.195548</td>\n",
       "      <td>82.477876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_skin</th>\n",
       "      <td>0.519419</td>\n",
       "      <td>1.067970</td>\n",
       "      <td>82.575321</td>\n",
       "      <td>76.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_eyes</th>\n",
       "      <td>0.511573</td>\n",
       "      <td>0.801791</td>\n",
       "      <td>80.982537</td>\n",
       "      <td>75.398230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_behind_head</th>\n",
       "      <td>0.683679</td>\n",
       "      <td>0.192901</td>\n",
       "      <td>74.784111</td>\n",
       "      <td>94.690265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_across_face</th>\n",
       "      <td>0.387151</td>\n",
       "      <td>1.616019</td>\n",
       "      <td>85.530608</td>\n",
       "      <td>67.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_tinted_lenses</th>\n",
       "      <td>0.374014</td>\n",
       "      <td>0.153134</td>\n",
       "      <td>86.835540</td>\n",
       "      <td>96.460177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_lenses</th>\n",
       "      <td>0.399434</td>\n",
       "      <td>0.466475</td>\n",
       "      <td>84.225676</td>\n",
       "      <td>87.256637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frames_too_heavy</th>\n",
       "      <td>0.314288</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>91.191710</td>\n",
       "      <td>96.283186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_covering_eyes</th>\n",
       "      <td>0.496969</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>82.594512</td>\n",
       "      <td>86.194690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hat_cap</th>\n",
       "      <td>0.412115</td>\n",
       "      <td>0.189095</td>\n",
       "      <td>84.897333</td>\n",
       "      <td>94.159292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil_over_face</th>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>95.509499</td>\n",
       "      <td>96.283186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_open</th>\n",
       "      <td>0.548080</td>\n",
       "      <td>0.956703</td>\n",
       "      <td>78.315103</td>\n",
       "      <td>66.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_of_other_faces_or_toys</th>\n",
       "      <td>0.054398</td>\n",
       "      <td>0.143940</td>\n",
       "      <td>98.810209</td>\n",
       "      <td>98.230088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loss_train  loss_val  acc_train    acc_val\n",
       "blurred                            0.477066  0.284701  83.554020  87.964602\n",
       "looking_away                       0.775122  0.704371  68.911917  77.699115\n",
       "ink_marked_creased                 0.163186  0.066722  93.935905  98.230088\n",
       "unnatural_skin_tone                0.298098  1.286963  92.208789  70.973451\n",
       "too_dark_light                     0.239507  0.558732  93.705623  87.964602\n",
       "washed_out                         0.039938  0.705906  98.368835  93.982301\n",
       "pixelation                         0.263314  0.209834  92.784494  94.867257\n",
       "hair_across_eyes                   0.335975  0.502080  87.891000  91.504425\n",
       "eyes_closed                        0.644777  0.539429  79.217041  86.371681\n",
       "varied_background                  0.319334  1.339677  87.929380  80.884956\n",
       "roll_pitch_yaw                     0.651660  0.987820  71.195548  82.477876\n",
       "flash_reflection_on_skin           0.519419  1.067970  82.575321  76.814159\n",
       "red_eyes                           0.511573  0.801791  80.982537  75.398230\n",
       "shadows_behind_head                0.683679  0.192901  74.784111  94.690265\n",
       "shadows_across_face                0.387151  1.616019  85.530608  67.964602\n",
       "dark_tinted_lenses                 0.374014  0.153134  86.835540  96.460177\n",
       "flash_reflection_on_lenses         0.399434  0.466475  84.225676  87.256637\n",
       "frames_too_heavy                   0.314288  0.120425  91.191710  96.283186\n",
       "frame_covering_eyes                0.496969  0.550900  82.594512  86.194690\n",
       "hat_cap                            0.412115  0.189095  84.897333  94.159292\n",
       "veil_over_face                     0.143541  0.114537  95.509499  96.283186\n",
       "mouth_open                         0.548080  0.956703  78.315103  66.371681\n",
       "presence_of_other_faces_or_toys    0.054398  0.143940  98.810209  98.230088"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = model.fit(train_features, \n",
    "                 np.hsplit(y_train, range(1, y_train.shape[1])), \n",
    "                 batch_size=32, \n",
    "                 epochs=3, \n",
    "                 validation_data=(val_features, np.hsplit(y_val, range(1, y_val.shape[1]))))\n",
    "\n",
    "save_history(hist.history, 'images/history.pdf')\n",
    "history_to_dataframe(hist.history, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = np.hsplit(y_val, range(1, y_val.shape[1]))\n",
    "y_preds = model.predict(val_features)\n",
    "\n",
    "save_heatmaps(y_trues, y_preds, output_file='images/heatmaps.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
