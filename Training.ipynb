{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from math import ceil\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.mrk_file import MRKFile\n",
    "from src.iso_standard import PhotographicRequirements\n",
    "from src.utils.plot import plot_confusion_matrix\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TRAIN_DUMP = 'data/train_dump.pkl'\n",
    "FILE_TRAIN_BOTTLENECKS = 'data/train_bottlenecks.pkl'\n",
    "\n",
    "FILE_VAL_DUMP = 'data/val_dump.pkl'\n",
    "FILE_VAL_BOTTLENECKS = 'data/val_bottlenecks.pkl'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = ['blurred', \n",
    "                'looking_away', \n",
    "                'ink_marked_creased', \n",
    "                'unnatural_skin_tone', \n",
    "                'too_dark_light', \n",
    "                'washed_out', \n",
    "                'pixelation', \n",
    "                'hair_across_eyes', \n",
    "                'eyes_closed', \n",
    "                'varied_background', \n",
    "                'roll_pitch_yaw', \n",
    "                'flash_reflection_on_skin', \n",
    "                'red_eyes', \n",
    "                'shadows_behind_head', \n",
    "                'shadows_across_face', \n",
    "                'dark_tinted_lenses', \n",
    "                'flash_reflection_on_lenses', \n",
    "                'frames_too_heavy', \n",
    "                'frame_covering_eyes', \n",
    "                'hat_cap', \n",
    "                'veil_over_face', \n",
    "                'mouth_open', \n",
    "                'presence_of_other_faces_or_toys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_to_dataframe(history, epoch=-1):\n",
    "    loss_train = np.array([history[name + '_loss'][epoch] for name in output_names])\n",
    "    loss_val = np.array([history['val_' + name + '_loss'][epoch] for name in output_names])\n",
    "    acc_train = np.array([history[name + '_acc'][epoch] for name in output_names]) * 100\n",
    "    acc_val = np.array([history['val_' + name + '_acc'][epoch] for name in output_names]) * 100\n",
    "\n",
    "    data = np.concatenate(([loss_train], [loss_val], [acc_train], [acc_val]), axis=0).T\n",
    "    return pd.DataFrame(data, columns=['loss_train', 'loss_val', 'acc_train', 'acc_val'], index=output_names)\n",
    "\n",
    "def load_proportions(file_txt):\n",
    "    prop_values = np.loadtxt(file_txt)\n",
    "    return pd.DataFrame(prop_values, index=output_names).T\n",
    "\n",
    "def plot_graph(subplot, train, val, title):\n",
    "    plt.subplot(*subplot)\n",
    "    plt.plot(train, label='train')\n",
    "    plt.plot(val, label='val')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "def save_history(history, output_file):\n",
    "    n_epochs = len(history['loss'])\n",
    "    n_graphs = len(output_names) * 2\n",
    "    n_cols = 2\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "\n",
    "    df_train_props = load_proportions('data/train_max_proportions.txt')\n",
    "    df_val_props = load_proportions('data/val_max_proportions.txt')\n",
    "    \n",
    "    plt.figure(figsize=(16, 100))\n",
    "    for i, name in zip(range(1, n_graphs, 2), output_names):\n",
    "        train_loss = history[name + '_loss']\n",
    "        train_acc = history[name + '_acc']\n",
    "        val_loss = history['val_' + name + '_loss']\n",
    "        val_acc = history['val_' + name + '_acc']\n",
    "\n",
    "        plot_graph((n_rows, n_cols, i), train_loss, val_loss, '{} ({})'.format(name, 'loss'))\n",
    "        plot_graph((n_rows, n_cols, i + 1), train_acc, val_acc, '{} ({})'.format(name, 'acc'))\n",
    "        plt.hlines(df_train_props[name], 0, n_epochs, linestyle=':', color='blue')\n",
    "        plt.hlines(df_val_props[name], 0, n_epochs, linestyle=':', color='orange')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "def save_heatmaps(y_trues, y_preds, output_file, figsize=(20, 20)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    n_graphs = len(output_names)\n",
    "    n_cols = 5\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "    labels = np.unique(y_trues)\n",
    "\n",
    "    for i, name, y_true, y_pred in zip(range(1, n_graphs + 1), output_names, y_trues, y_preds):\n",
    "        y_pred = np.argmax(y_pred, axis=-1)\n",
    "        conf_matrix = confusion_matrix(y_true.ravel(), y_pred, labels=labels)\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        plot_confusion_matrix(conf_matrix, \n",
    "                              target_names=['D', 'NC', 'C'], \n",
    "                              title=name, \n",
    "                              normalize=True)\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211 <class 'list'>\n",
      "(5211, 224, 224, 3) float32\n",
      "5211 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "train_image_files, x_train, train_mrks = pkl.load(open(FILE_TRAIN_DUMP, 'rb'))\n",
    "\n",
    "print(len(train_image_files), type(train_image_files))\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(len(train_mrks), type(train_mrks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 <class 'list'>\n",
      "(565, 224, 224, 3) float32\n",
      "565 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "val_image_files, x_val, val_mrks = pkl.load(open(FILE_VAL_DUMP, 'rb'))\n",
    "\n",
    "print(len(val_image_files), type(val_image_files))\n",
    "print(x_val.shape, x_val.dtype)\n",
    "print(len(val_mrks), type(val_mrks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Bottlenecks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211/5211 [==============================] - 7s 1ms/step\n",
      "565/565 [==============================] - 1s 1ms/step\n",
      "(5211, 7, 7, 1024) float32\n",
      "(565, 7, 7, 1024) float32\n"
     ]
    }
   ],
   "source": [
    "train_features = base_model.predict(x_train, batch_size=32, verbose=1)\n",
    "val_features = base_model.predict(x_val, batch_size=32, verbose=1)\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(val_features.shape, val_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 23) int8\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_values = np.array([mrk.photo_reqs.values() for mrk in train_mrks], dtype=np.int8)\n",
    "val_values = np.array([mrk.photo_reqs.values() for mrk in val_mrks], dtype=np.int8)\n",
    "\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump((train_features, train_values), open(FILE_TRAIN_BOTTLENECKS, 'wb'), protocol=-1)\n",
    "pkl.dump((val_features, val_values), open(FILE_VAL_BOTTLENECKS, 'wb'), protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 7, 7, 1024) float32\n",
      "(5211, 23) int8\n",
      "(565, 7, 7, 1024) float32\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_features, train_values = pkl.load(open(FILE_TRAIN_BOTTLENECKS, 'rb'))\n",
    "val_features, val_values = pkl.load(open(FILE_VAL_BOTTLENECKS, 'rb'))\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_features.shape, val_features.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode reqs values from [-1, 0, 1] => [0, 1, 2]\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_values.ravel())\n",
    "\n",
    "y_train = enc.transform(train_values.ravel()).reshape(train_values.shape)\n",
    "y_val = enc.transform(val_values.ravel()).reshape(val_values.shape)\n",
    "\n",
    "assert(y_train.shape == train_values.shape)\n",
    "assert(y_val.shape == val_values.shape)\n",
    "assert(np.all(y_train == train_values + 1))\n",
    "assert(np.all(y_val == val_values + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_dense_layer(inputs, name):\n",
    "    r = Dropout(rate=0.5)(inputs)\n",
    "    return Dense(units=3, activation='softmax', name=name)(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 7, 7, 1024)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1024)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "blurred (Dense)                 (None, 3)            3075        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "looking_away (Dense)            (None, 3)            3075        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ink_marked_creased (Dense)      (None, 3)            3075        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unnatural_skin_tone (Dense)     (None, 3)            3075        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "too_dark_light (Dense)          (None, 3)            3075        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "washed_out (Dense)              (None, 3)            3075        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pixelation (Dense)              (None, 3)            3075        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hair_across_eyes (Dense)        (None, 3)            3075        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "eyes_closed (Dense)             (None, 3)            3075        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "varied_background (Dense)       (None, 3)            3075        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "roll_pitch_yaw (Dense)          (None, 3)            3075        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_skin (Dense (None, 3)            3075        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "red_eyes (Dense)                (None, 3)            3075        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "shadows_behind_head (Dense)     (None, 3)            3075        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "shadows_across_face (Dense)     (None, 3)            3075        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dark_tinted_lenses (Dense)      (None, 3)            3075        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_lenses (Den (None, 3)            3075        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "frames_too_heavy (Dense)        (None, 3)            3075        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "frame_covering_eyes (Dense)     (None, 3)            3075        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "hat_cap (Dense)                 (None, 3)            3075        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "veil_over_face (Dense)          (None, 3)            3075        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mouth_open (Dense)              (None, 3)            3075        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "presence_of_other_faces_or_toys (None, 3)            3075        dropout_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,725\n",
      "Trainable params: 70,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=train_features.shape[1:], name='inputs')\n",
    "avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "r2 = dropout_dense_layer(avg_pool, name=output_names[0])\n",
    "r3 = dropout_dense_layer(avg_pool, name=output_names[1])\n",
    "r4 = dropout_dense_layer(avg_pool, name=output_names[2])\n",
    "r5 = dropout_dense_layer(avg_pool, name=output_names[3])\n",
    "r6 = dropout_dense_layer(avg_pool, name=output_names[4])\n",
    "r7 = dropout_dense_layer(avg_pool, name=output_names[5])\n",
    "r8 = dropout_dense_layer(avg_pool, name=output_names[6])\n",
    "r9 = dropout_dense_layer(avg_pool, name=output_names[7])\n",
    "r10 = dropout_dense_layer(avg_pool, name=output_names[8])\n",
    "r11 = dropout_dense_layer(avg_pool, name=output_names[9])\n",
    "r12 = dropout_dense_layer(avg_pool, name=output_names[10])\n",
    "r13 = dropout_dense_layer(avg_pool, name=output_names[11])\n",
    "r14 = dropout_dense_layer(avg_pool, name=output_names[12])\n",
    "r15 = dropout_dense_layer(avg_pool, name=output_names[13])\n",
    "r16 = dropout_dense_layer(avg_pool, name=output_names[14])\n",
    "r17 = dropout_dense_layer(avg_pool, name=output_names[15])\n",
    "r18 = dropout_dense_layer(avg_pool, name=output_names[16])\n",
    "r19 = dropout_dense_layer(avg_pool, name=output_names[17])\n",
    "r20 = dropout_dense_layer(avg_pool, name=output_names[18])\n",
    "r21 = dropout_dense_layer(avg_pool, name=output_names[19])\n",
    "r22 = dropout_dense_layer(avg_pool, name=output_names[20])\n",
    "r23 = dropout_dense_layer(avg_pool, name=output_names[21])\n",
    "r24 = dropout_dense_layer(avg_pool, name=output_names[22])\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=[r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15, r16, r17, r18, r19, r20, r21, r22, r23, r24], \n",
    "              name='icaonet')\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5211 samples, validate on 565 samples\n",
      "Epoch 1/3\n",
      " - 4s - loss: 6.0478 - blurred_loss: 0.3429 - looking_away_loss: 0.6083 - ink_marked_creased_loss: 0.0822 - unnatural_skin_tone_loss: 0.1488 - too_dark_light_loss: 0.1554 - washed_out_loss: 9.0763e-05 - pixelation_loss: 0.2157 - hair_across_eyes_loss: 0.1814 - eyes_closed_loss: 0.4292 - varied_background_loss: 0.2152 - roll_pitch_yaw_loss: 0.5419 - flash_reflection_on_skin_loss: 0.3095 - red_eyes_loss: 0.3261 - shadows_behind_head_loss: 0.4972 - shadows_across_face_loss: 0.2936 - dark_tinted_lenses_loss: 0.1700 - flash_reflection_on_lenses_loss: 0.2952 - frames_too_heavy_loss: 0.1717 - frame_covering_eyes_loss: 0.3566 - hat_cap_loss: 0.2218 - veil_over_face_loss: 0.0537 - mouth_open_loss: 0.4279 - presence_of_other_faces_or_toys_loss: 0.0034 - blurred_acc: 0.8699 - looking_away_acc: 0.7588 - ink_marked_creased_acc: 0.9660 - unnatural_skin_tone_acc: 0.9438 - too_dark_light_acc: 0.9516 - washed_out_acc: 1.0000 - pixelation_acc: 0.9284 - hair_across_eyes_acc: 0.9278 - eyes_closed_acc: 0.8463 - varied_background_acc: 0.9211 - roll_pitch_yaw_acc: 0.7595 - flash_reflection_on_skin_acc: 0.8854 - red_eyes_acc: 0.8720 - shadows_behind_head_acc: 0.8091 - shadows_across_face_acc: 0.8918 - dark_tinted_lenses_acc: 0.9397 - flash_reflection_on_lenses_acc: 0.8801 - frames_too_heavy_acc: 0.9432 - frame_covering_eyes_acc: 0.8599 - hat_cap_acc: 0.9150 - veil_over_face_acc: 0.9827 - mouth_open_acc: 0.8140 - presence_of_other_faces_or_toys_acc: 0.9985 - val_loss: 18.2837 - val_blurred_loss: 0.2919 - val_looking_away_loss: 0.7021 - val_ink_marked_creased_loss: 0.0703 - val_unnatural_skin_tone_loss: 2.3934 - val_too_dark_light_loss: 0.6098 - val_washed_out_loss: 0.9699 - val_pixelation_loss: 0.2237 - val_hair_across_eyes_loss: 0.9789 - val_eyes_closed_loss: 0.5713 - val_varied_background_loss: 2.2905 - val_roll_pitch_yaw_loss: 1.2243 - val_flash_reflection_on_skin_loss: 1.7229 - val_red_eyes_loss: 0.8436 - val_shadows_behind_head_loss: 0.1169 - val_shadows_across_face_loss: 2.0851 - val_dark_tinted_lenses_loss: 0.1136 - val_flash_reflection_on_lenses_loss: 0.5092 - val_frames_too_heavy_loss: 0.1513 - val_frame_covering_eyes_loss: 0.6632 - val_hat_cap_loss: 0.1580 - val_veil_over_face_loss: 0.0369 - val_mouth_open_loss: 1.2852 - val_presence_of_other_faces_or_toys_loss: 0.2718 - val_blurred_acc: 0.8832 - val_looking_away_acc: 0.7876 - val_ink_marked_creased_acc: 0.9770 - val_unnatural_skin_tone_acc: 0.7416 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9469 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8708 - val_varied_background_acc: 0.8319 - val_roll_pitch_yaw_acc: 0.8319 - val_flash_reflection_on_skin_acc: 0.7451 - val_red_eyes_acc: 0.7681 - val_shadows_behind_head_acc: 0.9735 - val_shadows_across_face_acc: 0.6867 - val_dark_tinted_lenses_acc: 0.9841 - val_flash_reflection_on_lenses_acc: 0.9027 - val_frames_too_heavy_acc: 0.9522 - val_frame_covering_eyes_acc: 0.8761 - val_hat_cap_acc: 0.9504 - val_veil_over_face_acc: 0.9894 - val_mouth_open_acc: 0.7044 - val_presence_of_other_faces_or_toys_acc: 0.9805\n",
      "Epoch 2/3\n",
      " - 4s - loss: 6.0684 - blurred_loss: 0.3382 - looking_away_loss: 0.6195 - ink_marked_creased_loss: 0.0830 - unnatural_skin_tone_loss: 0.1447 - too_dark_light_loss: 0.1511 - washed_out_loss: 6.0012e-04 - pixelation_loss: 0.2218 - hair_across_eyes_loss: 0.1934 - eyes_closed_loss: 0.4329 - varied_background_loss: 0.2189 - roll_pitch_yaw_loss: 0.5521 - flash_reflection_on_skin_loss: 0.3105 - red_eyes_loss: 0.3312 - shadows_behind_head_loss: 0.4960 - shadows_across_face_loss: 0.2864 - dark_tinted_lenses_loss: 0.1723 - flash_reflection_on_lenses_loss: 0.2918 - frames_too_heavy_loss: 0.1634 - frame_covering_eyes_loss: 0.3559 - hat_cap_loss: 0.2163 - veil_over_face_loss: 0.0545 - mouth_open_loss: 0.4320 - presence_of_other_faces_or_toys_loss: 0.0019 - blurred_acc: 0.8722 - looking_away_acc: 0.7559 - ink_marked_creased_acc: 0.9655 - unnatural_skin_tone_acc: 0.9461 - too_dark_light_acc: 0.9491 - washed_out_acc: 0.9998 - pixelation_acc: 0.9259 - hair_across_eyes_acc: 0.9282 - eyes_closed_acc: 0.8455 - varied_background_acc: 0.9179 - roll_pitch_yaw_acc: 0.7536 - flash_reflection_on_skin_acc: 0.8824 - red_eyes_acc: 0.8695 - shadows_behind_head_acc: 0.8000 - shadows_across_face_acc: 0.8954 - dark_tinted_lenses_acc: 0.9365 - flash_reflection_on_lenses_acc: 0.8812 - frames_too_heavy_acc: 0.9436 - frame_covering_eyes_acc: 0.8661 - hat_cap_acc: 0.9192 - veil_over_face_acc: 0.9823 - mouth_open_acc: 0.8152 - presence_of_other_faces_or_toys_acc: 0.9994 - val_loss: 18.3845 - val_blurred_loss: 0.3053 - val_looking_away_loss: 0.7445 - val_ink_marked_creased_loss: 0.1937 - val_unnatural_skin_tone_loss: 2.2453 - val_too_dark_light_loss: 0.5250 - val_washed_out_loss: 0.9699 - val_pixelation_loss: 0.2330 - val_hair_across_eyes_loss: 1.0403 - val_eyes_closed_loss: 0.5906 - val_varied_background_loss: 2.3302 - val_roll_pitch_yaw_loss: 1.1686 - val_flash_reflection_on_skin_loss: 1.9726 - val_red_eyes_loss: 0.8537 - val_shadows_behind_head_loss: 0.1140 - val_shadows_across_face_loss: 1.9970 - val_dark_tinted_lenses_loss: 0.1067 - val_flash_reflection_on_lenses_loss: 0.5023 - val_frames_too_heavy_loss: 0.1328 - val_frame_covering_eyes_loss: 0.6728 - val_hat_cap_loss: 0.1620 - val_veil_over_face_loss: 0.0357 - val_mouth_open_loss: 1.2057 - val_presence_of_other_faces_or_toys_loss: 0.2829 - val_blurred_acc: 0.8761 - val_looking_away_acc: 0.7858 - val_ink_marked_creased_acc: 0.8814 - val_unnatural_skin_tone_acc: 0.7381 - val_too_dark_light_acc: 0.8726 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9416 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8708 - val_varied_background_acc: 0.8319 - val_roll_pitch_yaw_acc: 0.8336 - val_flash_reflection_on_skin_acc: 0.6708 - val_red_eyes_acc: 0.7646 - val_shadows_behind_head_acc: 0.9770 - val_shadows_across_face_acc: 0.6832 - val_dark_tinted_lenses_acc: 0.9876 - val_flash_reflection_on_lenses_acc: 0.9115 - val_frames_too_heavy_acc: 0.9558 - val_frame_covering_eyes_acc: 0.8761 - val_hat_cap_acc: 0.9504 - val_veil_over_face_acc: 0.9947 - val_mouth_open_acc: 0.7186 - val_presence_of_other_faces_or_toys_acc: 0.9823\n",
      "Epoch 3/3\n",
      " - 4s - loss: 6.0636 - blurred_loss: 0.3413 - looking_away_loss: 0.6143 - ink_marked_creased_loss: 0.0740 - unnatural_skin_tone_loss: 0.1399 - too_dark_light_loss: 0.1423 - washed_out_loss: 3.0788e-04 - pixelation_loss: 0.2296 - hair_across_eyes_loss: 0.1942 - eyes_closed_loss: 0.4292 - varied_background_loss: 0.2164 - roll_pitch_yaw_loss: 0.5508 - flash_reflection_on_skin_loss: 0.2954 - red_eyes_loss: 0.3358 - shadows_behind_head_loss: 0.4881 - shadows_across_face_loss: 0.2828 - dark_tinted_lenses_loss: 0.1765 - flash_reflection_on_lenses_loss: 0.3011 - frames_too_heavy_loss: 0.1673 - frame_covering_eyes_loss: 0.3597 - hat_cap_loss: 0.2142 - veil_over_face_loss: 0.0671 - mouth_open_loss: 0.4401 - presence_of_other_faces_or_toys_loss: 0.0031 - blurred_acc: 0.8733 - looking_away_acc: 0.7572 - ink_marked_creased_acc: 0.9676 - unnatural_skin_tone_acc: 0.9468 - too_dark_light_acc: 0.9503 - washed_out_acc: 0.9998 - pixelation_acc: 0.9301 - hair_across_eyes_acc: 0.9236 - eyes_closed_acc: 0.8432 - varied_background_acc: 0.9146 - roll_pitch_yaw_acc: 0.7592 - flash_reflection_on_skin_acc: 0.8875 - red_eyes_acc: 0.8670 - shadows_behind_head_acc: 0.8010 - shadows_across_face_acc: 0.8964 - dark_tinted_lenses_acc: 0.9338 - flash_reflection_on_lenses_acc: 0.8772 - frames_too_heavy_acc: 0.9426 - frame_covering_eyes_acc: 0.8657 - hat_cap_acc: 0.9142 - veil_over_face_acc: 0.9770 - mouth_open_acc: 0.8110 - presence_of_other_faces_or_toys_acc: 0.9990 - val_loss: 19.1678 - val_blurred_loss: 0.2942 - val_looking_away_loss: 0.7025 - val_ink_marked_creased_loss: 0.1047 - val_unnatural_skin_tone_loss: 2.3126 - val_too_dark_light_loss: 0.7918 - val_washed_out_loss: 0.9700 - val_pixelation_loss: 0.2182 - val_hair_across_eyes_loss: 1.0235 - val_eyes_closed_loss: 0.6011 - val_varied_background_loss: 2.2834 - val_roll_pitch_yaw_loss: 1.0218 - val_flash_reflection_on_skin_loss: 2.0232 - val_red_eyes_loss: 0.9929 - val_shadows_behind_head_loss: 0.1212 - val_shadows_across_face_loss: 2.5112 - val_dark_tinted_lenses_loss: 0.1111 - val_flash_reflection_on_lenses_loss: 0.5095 - val_frames_too_heavy_loss: 0.1011 - val_frame_covering_eyes_loss: 0.7356 - val_hat_cap_loss: 0.1665 - val_veil_over_face_loss: 0.0444 - val_mouth_open_loss: 1.2441 - val_presence_of_other_faces_or_toys_loss: 0.2834 - val_blurred_acc: 0.8761 - val_looking_away_acc: 0.7947 - val_ink_marked_creased_acc: 0.9416 - val_unnatural_skin_tone_acc: 0.7115 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8761 - val_varied_background_acc: 0.8265 - val_roll_pitch_yaw_acc: 0.8336 - val_flash_reflection_on_skin_acc: 0.6513 - val_red_eyes_acc: 0.7487 - val_shadows_behind_head_acc: 0.9664 - val_shadows_across_face_acc: 0.6903 - val_dark_tinted_lenses_acc: 0.9876 - val_flash_reflection_on_lenses_acc: 0.9133 - val_frames_too_heavy_acc: 0.9628 - val_frame_covering_eyes_acc: 0.8726 - val_hat_cap_acc: 0.9451 - val_veil_over_face_acc: 0.9858 - val_mouth_open_acc: 0.6867 - val_presence_of_other_faces_or_toys_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = model.fit(train_features, \n",
    "                 np.hsplit(y_train, range(1, y_train.shape[1])), \n",
    "                 batch_size=32, \n",
    "                 epochs=3, \n",
    "                 validation_data=(val_features, np.hsplit(y_val, range(1, y_val.shape[1]))), \n",
    "                 verbose=2)\n",
    "\n",
    "save_history(hist.history, 'images/history.pdf')\n",
    "\n",
    "plot_graph((1, 1, 1), hist.history['loss'], hist.history['val_loss'], 'loss')\n",
    "plt.savefig('images/loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blurred</th>\n",
       "      <td>0.341263</td>\n",
       "      <td>0.294242</td>\n",
       "      <td>87.334485</td>\n",
       "      <td>87.610619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking_away</th>\n",
       "      <td>0.614337</td>\n",
       "      <td>0.702454</td>\n",
       "      <td>75.724429</td>\n",
       "      <td>79.469027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ink_marked_creased</th>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.104652</td>\n",
       "      <td>96.756860</td>\n",
       "      <td>94.159292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unnatural_skin_tone</th>\n",
       "      <td>0.139893</td>\n",
       "      <td>2.312552</td>\n",
       "      <td>94.684322</td>\n",
       "      <td>71.150442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too_dark_light</th>\n",
       "      <td>0.142336</td>\n",
       "      <td>0.791758</td>\n",
       "      <td>95.029745</td>\n",
       "      <td>87.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washed_out</th>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.969954</td>\n",
       "      <td>99.980810</td>\n",
       "      <td>93.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixelation</th>\n",
       "      <td>0.229585</td>\n",
       "      <td>0.218213</td>\n",
       "      <td>93.014776</td>\n",
       "      <td>94.867257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair_across_eyes</th>\n",
       "      <td>0.194210</td>\n",
       "      <td>1.023546</td>\n",
       "      <td>92.362310</td>\n",
       "      <td>91.504425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes_closed</th>\n",
       "      <td>0.429214</td>\n",
       "      <td>0.601103</td>\n",
       "      <td>84.321627</td>\n",
       "      <td>87.610619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varied_background</th>\n",
       "      <td>0.216405</td>\n",
       "      <td>2.283364</td>\n",
       "      <td>91.460372</td>\n",
       "      <td>82.654867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll_pitch_yaw</th>\n",
       "      <td>0.550822</td>\n",
       "      <td>1.021771</td>\n",
       "      <td>75.916331</td>\n",
       "      <td>83.362832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_skin</th>\n",
       "      <td>0.295379</td>\n",
       "      <td>2.023183</td>\n",
       "      <td>88.754558</td>\n",
       "      <td>65.132743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_eyes</th>\n",
       "      <td>0.335814</td>\n",
       "      <td>0.992850</td>\n",
       "      <td>86.701209</td>\n",
       "      <td>74.867257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_behind_head</th>\n",
       "      <td>0.488053</td>\n",
       "      <td>0.121224</td>\n",
       "      <td>80.099789</td>\n",
       "      <td>96.637168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_across_face</th>\n",
       "      <td>0.282818</td>\n",
       "      <td>2.511169</td>\n",
       "      <td>89.637306</td>\n",
       "      <td>69.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_tinted_lenses</th>\n",
       "      <td>0.176530</td>\n",
       "      <td>0.111142</td>\n",
       "      <td>93.379390</td>\n",
       "      <td>98.761062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_lenses</th>\n",
       "      <td>0.301051</td>\n",
       "      <td>0.509548</td>\n",
       "      <td>87.718288</td>\n",
       "      <td>91.327434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frames_too_heavy</th>\n",
       "      <td>0.167287</td>\n",
       "      <td>0.101089</td>\n",
       "      <td>94.262138</td>\n",
       "      <td>96.283186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_covering_eyes</th>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.735558</td>\n",
       "      <td>86.566878</td>\n",
       "      <td>87.256637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hat_cap</th>\n",
       "      <td>0.214197</td>\n",
       "      <td>0.166517</td>\n",
       "      <td>91.421992</td>\n",
       "      <td>94.513274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil_over_face</th>\n",
       "      <td>0.067123</td>\n",
       "      <td>0.044395</td>\n",
       "      <td>97.697179</td>\n",
       "      <td>98.584071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_open</th>\n",
       "      <td>0.440100</td>\n",
       "      <td>1.244084</td>\n",
       "      <td>81.097678</td>\n",
       "      <td>68.672566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_of_other_faces_or_toys</th>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.283447</td>\n",
       "      <td>99.904049</td>\n",
       "      <td>98.230088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loss_train  loss_val  acc_train    acc_val\n",
       "blurred                            0.341263  0.294242  87.334485  87.610619\n",
       "looking_away                       0.614337  0.702454  75.724429  79.469027\n",
       "ink_marked_creased                 0.074000  0.104652  96.756860  94.159292\n",
       "unnatural_skin_tone                0.139893  2.312552  94.684322  71.150442\n",
       "too_dark_light                     0.142336  0.791758  95.029745  87.964602\n",
       "washed_out                         0.000308  0.969954  99.980810  93.982301\n",
       "pixelation                         0.229585  0.218213  93.014776  94.867257\n",
       "hair_across_eyes                   0.194210  1.023546  92.362310  91.504425\n",
       "eyes_closed                        0.429214  0.601103  84.321627  87.610619\n",
       "varied_background                  0.216405  2.283364  91.460372  82.654867\n",
       "roll_pitch_yaw                     0.550822  1.021771  75.916331  83.362832\n",
       "flash_reflection_on_skin           0.295379  2.023183  88.754558  65.132743\n",
       "red_eyes                           0.335814  0.992850  86.701209  74.867257\n",
       "shadows_behind_head                0.488053  0.121224  80.099789  96.637168\n",
       "shadows_across_face                0.282818  2.511169  89.637306  69.026549\n",
       "dark_tinted_lenses                 0.176530  0.111142  93.379390  98.761062\n",
       "flash_reflection_on_lenses         0.301051  0.509548  87.718288  91.327434\n",
       "frames_too_heavy                   0.167287  0.101089  94.262138  96.283186\n",
       "frame_covering_eyes                0.359744  0.735558  86.566878  87.256637\n",
       "hat_cap                            0.214197  0.166517  91.421992  94.513274\n",
       "veil_over_face                     0.067123  0.044395  97.697179  98.584071\n",
       "mouth_open                         0.440100  1.244084  81.097678  68.672566\n",
       "presence_of_other_faces_or_toys    0.003137  0.283447  99.904049  98.230088"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_to_dataframe(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = np.hsplit(y_val, range(1, y_val.shape[1]))\n",
    "y_preds = model.predict(val_features)\n",
    "\n",
    "save_heatmaps(y_trues, y_preds, output_file='images/heatmaps.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
