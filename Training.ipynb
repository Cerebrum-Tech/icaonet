{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from math import ceil\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.mrk_file import MRKFile\n",
    "from src.iso_standard import PhotographicRequirements\n",
    "from src.utils.plot import plot_confusion_matrix\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TRAIN_DUMP = 'data/train_dump.pkl'\n",
    "FILE_TRAIN_BOTTLENECKS = 'data/train_bottlenecks.pkl'\n",
    "\n",
    "FILE_VAL_DUMP = 'data/val_dump.pkl'\n",
    "FILE_VAL_BOTTLENECKS = 'data/val_bottlenecks.pkl'\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = ['blurred', \n",
    "                'looking_away', \n",
    "                'ink_marked_creased', \n",
    "                'unnatural_skin_tone', \n",
    "                'too_dark_light', \n",
    "                'washed_out', \n",
    "                'pixelation', \n",
    "                'hair_across_eyes', \n",
    "                'eyes_closed', \n",
    "                'varied_background', \n",
    "                'roll_pitch_yaw', \n",
    "                'flash_reflection_on_skin', \n",
    "                'red_eyes', \n",
    "                'shadows_behind_head', \n",
    "                'shadows_across_face', \n",
    "                'dark_tinted_lenses', \n",
    "                'flash_reflection_on_lenses', \n",
    "                'frames_too_heavy', \n",
    "                'frame_covering_eyes', \n",
    "                'hat_cap', \n",
    "                'veil_over_face', \n",
    "                'mouth_open', \n",
    "                'presence_of_other_faces_or_toys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_to_dataframe(history, epoch=-1):\n",
    "    loss_train = np.array([history[name + '_loss'][epoch] for name in output_names])\n",
    "    loss_val = np.array([history['val_' + name + '_loss'][epoch] for name in output_names])\n",
    "    acc_train = np.array([history[name + '_acc'][epoch] for name in output_names]) * 100\n",
    "    acc_val = np.array([history['val_' + name + '_acc'][epoch] for name in output_names]) * 100\n",
    "\n",
    "    data = np.concatenate(([loss_train], [loss_val], [acc_train], [acc_val]), axis=0).T\n",
    "    return pd.DataFrame(data, columns=['loss_train', 'loss_val', 'acc_train', 'acc_val'], index=output_names)\n",
    "\n",
    "def save_history(history, output_file):\n",
    "    n_graphs = len(output_names) * 2\n",
    "    n_cols = 2\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "\n",
    "    plt.figure(figsize=(16, 100))\n",
    "    for i, name in zip(range(1, n_graphs, 2), output_names):\n",
    "        loss_train = history[name + '_loss']\n",
    "        loss_val = history['val_' + name + '_loss']\n",
    "        acc_train = history[name + '_acc']\n",
    "        acc_val = history['val_' + name + '_acc']\n",
    "\n",
    "        train_metrics = [loss_train, acc_train]\n",
    "        val_metrics = [loss_val, acc_val]\n",
    "        metrics = ['loss', 'acc']\n",
    "        for sub, train, val, metric in zip([i, i + 1], train_metrics, val_metrics, metrics):\n",
    "            plt.subplot(n_rows, n_cols, sub)\n",
    "            plt.plot(train, label='train')\n",
    "            plt.plot(val, label='val')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel(metric)\n",
    "            plt.title('{} ({})'.format(name, metric))\n",
    "            plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "def save_heatmaps(y_trues, y_preds, output_file, figsize=(20, 20)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    n_graphs = len(output_names)\n",
    "    n_cols = 5\n",
    "    n_rows = ceil(n_graphs / n_cols)\n",
    "    labels = np.unique(y_trues)\n",
    "\n",
    "    for i, name, y_true, y_pred in zip(range(1, n_graphs + 1), output_names, y_trues, y_preds):\n",
    "        y_pred = np.argmax(y_pred, axis=-1)\n",
    "        conf_matrix = confusion_matrix(y_true.ravel(), y_pred, labels=labels)\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        plot_confusion_matrix(conf_matrix, \n",
    "                              target_names=['D', 'NC', 'C'], \n",
    "                              title=name, \n",
    "                              normalize=True)\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211 <class 'list'>\n",
      "(5211, 224, 224, 3) float32\n",
      "5211 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "train_image_files, x_train, train_mrks = pkl.load(open(FILE_TRAIN_DUMP, 'rb'))\n",
    "\n",
    "print(len(train_image_files), type(train_image_files))\n",
    "print(x_train.shape, x_train.dtype)\n",
    "print(len(train_mrks), type(train_mrks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 <class 'list'>\n",
      "(565, 224, 224, 3) float32\n",
      "565 <class 'src.mrk_file.MRKFile'>\n"
     ]
    }
   ],
   "source": [
    "val_image_files, x_val, val_mrks = pkl.load(open(FILE_VAL_DUMP, 'rb'))\n",
    "\n",
    "print(len(val_image_files), type(val_image_files))\n",
    "print(x_val.shape, x_val.dtype)\n",
    "print(len(val_mrks), type(val_mrks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Bottlenecks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211/5211 [==============================] - 7s 1ms/step\n",
      "565/565 [==============================] - 1s 1ms/step\n",
      "(5211, 7, 7, 1024) float32\n",
      "(565, 7, 7, 1024) float32\n"
     ]
    }
   ],
   "source": [
    "train_features = base_model.predict(x_train, batch_size=32, verbose=1)\n",
    "val_features = base_model.predict(x_val, batch_size=32, verbose=1)\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(val_features.shape, val_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 23) int8\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_values = np.array([mrk.photo_reqs.values() for mrk in train_mrks], dtype=np.int8)\n",
    "val_values = np.array([mrk.photo_reqs.values() for mrk in val_mrks], dtype=np.int8)\n",
    "\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump((train_features, train_values), open(FILE_TRAIN_BOTTLENECKS, 'wb'), protocol=-1)\n",
    "pkl.dump((val_features, val_values), open(FILE_VAL_BOTTLENECKS, 'wb'), protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5211, 7, 7, 1024) float32\n",
      "(5211, 23) int8\n",
      "(565, 7, 7, 1024) float32\n",
      "(565, 23) int8\n"
     ]
    }
   ],
   "source": [
    "train_features, train_values = pkl.load(open(FILE_TRAIN_BOTTLENECKS, 'rb'))\n",
    "val_features, val_values = pkl.load(open(FILE_VAL_BOTTLENECKS, 'rb'))\n",
    "\n",
    "print(train_features.shape, train_features.dtype)\n",
    "print(train_values.shape, train_values.dtype)\n",
    "print(val_features.shape, val_features.dtype)\n",
    "print(val_values.shape, val_values.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode reqs values from [-1, 0, 1] => [0, 1, 2]\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_values.ravel())\n",
    "\n",
    "y_train = enc.transform(train_values.ravel()).reshape(train_values.shape)\n",
    "y_val = enc.transform(val_values.ravel()).reshape(val_values.shape)\n",
    "\n",
    "assert(y_train.shape == train_values.shape)\n",
    "assert(y_val.shape == val_values.shape)\n",
    "assert(np.all(y_train == train_values + 1))\n",
    "assert(np.all(y_val == val_values + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 7, 7, 1024)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blurred (Dense)                 (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "looking_away (Dense)            (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ink_marked_creased (Dense)      (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "unnatural_skin_tone (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "too_dark_light (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "washed_out (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "pixelation (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "hair_across_eyes (Dense)        (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "eyes_closed (Dense)             (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "varied_background (Dense)       (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "roll_pitch_yaw (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_skin (Dense (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "red_eyes (Dense)                (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "shadows_behind_head (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "shadows_across_face (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dark_tinted_lenses (Dense)      (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flash_reflection_on_lenses (Den (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "frames_too_heavy (Dense)        (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "frame_covering_eyes (Dense)     (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "hat_cap (Dense)                 (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "veil_over_face (Dense)          (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mouth_open (Dense)              (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "presence_of_other_faces_or_toys (None, 3)            3075        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 70,725\n",
      "Trainable params: 70,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=train_features.shape[1:], name='inputs')\n",
    "avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "r2 = Dense(units=3, activation='softmax', name=output_names[0])(avg_pool)\n",
    "r3 = Dense(units=3, activation='softmax', name=output_names[1])(avg_pool)\n",
    "r4 = Dense(units=3, activation='softmax', name=output_names[2])(avg_pool)\n",
    "r5 = Dense(units=3, activation='softmax', name=output_names[3])(avg_pool)\n",
    "r6 = Dense(units=3, activation='softmax', name=output_names[4])(avg_pool)\n",
    "r7 = Dense(units=3, activation='softmax', name=output_names[5])(avg_pool)\n",
    "r8 = Dense(units=3, activation='softmax', name=output_names[6])(avg_pool)\n",
    "r9 = Dense(units=3, activation='softmax', name=output_names[7])(avg_pool)\n",
    "r10 = Dense(units=3, activation='softmax', name=output_names[8])(avg_pool)\n",
    "r11 = Dense(units=3, activation='softmax', name=output_names[9])(avg_pool)\n",
    "r12 = Dense(units=3, activation='softmax', name=output_names[10])(avg_pool)\n",
    "r13 = Dense(units=3, activation='softmax', name=output_names[11])(avg_pool)\n",
    "r14 = Dense(units=3, activation='softmax', name=output_names[12])(avg_pool)\n",
    "r15 = Dense(units=3, activation='softmax', name=output_names[13])(avg_pool)\n",
    "r16 = Dense(units=3, activation='softmax', name=output_names[14])(avg_pool)\n",
    "r17 = Dense(units=3, activation='softmax', name=output_names[15])(avg_pool)\n",
    "r18 = Dense(units=3, activation='softmax', name=output_names[16])(avg_pool)\n",
    "r19 = Dense(units=3, activation='softmax', name=output_names[17])(avg_pool)\n",
    "r20 = Dense(units=3, activation='softmax', name=output_names[18])(avg_pool)\n",
    "r21 = Dense(units=3, activation='softmax', name=output_names[19])(avg_pool)\n",
    "r22 = Dense(units=3, activation='softmax', name=output_names[20])(avg_pool)\n",
    "r23 = Dense(units=3, activation='softmax', name=output_names[21])(avg_pool)\n",
    "r24 = Dense(units=3, activation='softmax', name=output_names[22])(avg_pool)\n",
    "\n",
    "model = Model(inputs=inputs, \n",
    "              outputs=[r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15, r16, r17, r18, r19, r20, r21, r22, r23, r24], \n",
    "              name='icaonet')\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5211 samples, validate on 565 samples\n",
      "Epoch 1/3\n",
      "5211/5211 [==============================] - 7s 1ms/step - loss: 8.8461 - blurred_loss: 0.5113 - looking_away_loss: 0.7947 - ink_marked_creased_loss: 0.1479 - unnatural_skin_tone_loss: 0.2904 - too_dark_light_loss: 0.2532 - washed_out_loss: 0.0459 - pixelation_loss: 0.3082 - hair_across_eyes_loss: 0.3047 - eyes_closed_loss: 0.5732 - varied_background_loss: 0.3574 - roll_pitch_yaw_loss: 0.6428 - flash_reflection_on_skin_loss: 0.4576 - red_eyes_loss: 0.4137 - shadows_behind_head_loss: 0.6668 - shadows_across_face_loss: 0.3831 - dark_tinted_lenses_loss: 0.2565 - flash_reflection_on_lenses_loss: 0.4021 - frames_too_heavy_loss: 0.3368 - frame_covering_eyes_loss: 0.5104 - hat_cap_loss: 0.3394 - veil_over_face_loss: 0.2215 - mouth_open_loss: 0.5897 - presence_of_other_faces_or_toys_loss: 0.0389 - blurred_acc: 0.8292 - looking_away_acc: 0.6822 - ink_marked_creased_acc: 0.9449 - unnatural_skin_tone_acc: 0.9211 - too_dark_light_acc: 0.9390 - washed_out_acc: 0.9845 - pixelation_acc: 0.9133 - hair_across_eyes_acc: 0.8883 - eyes_closed_acc: 0.8094 - varied_background_acc: 0.8605 - roll_pitch_yaw_acc: 0.7102 - flash_reflection_on_skin_acc: 0.8386 - red_eyes_acc: 0.8415 - shadows_behind_head_acc: 0.7540 - shadows_across_face_acc: 0.8588 - dark_tinted_lenses_acc: 0.9073 - flash_reflection_on_lenses_acc: 0.8355 - frames_too_heavy_acc: 0.9008 - frame_covering_eyes_acc: 0.8240 - hat_cap_acc: 0.8724 - veil_over_face_acc: 0.9321 - mouth_open_acc: 0.7655 - presence_of_other_faces_or_toys_acc: 0.9948 - val_loss: 13.7984 - val_blurred_loss: 0.3591 - val_looking_away_loss: 0.7306 - val_ink_marked_creased_loss: 0.2056 - val_unnatural_skin_tone_loss: 1.3241 - val_too_dark_light_loss: 0.5105 - val_washed_out_loss: 0.6642 - val_pixelation_loss: 0.2517 - val_hair_across_eyes_loss: 0.6680 - val_eyes_closed_loss: 0.5234 - val_varied_background_loss: 1.2682 - val_roll_pitch_yaw_loss: 0.8797 - val_flash_reflection_on_skin_loss: 1.0141 - val_red_eyes_loss: 0.8477 - val_shadows_behind_head_loss: 0.1819 - val_shadows_across_face_loss: 1.6231 - val_dark_tinted_lenses_loss: 0.1230 - val_flash_reflection_on_lenses_loss: 0.4471 - val_frames_too_heavy_loss: 0.1052 - val_frame_covering_eyes_loss: 0.5365 - val_hat_cap_loss: 0.1818 - val_veil_over_face_loss: 0.1736 - val_mouth_open_loss: 1.0416 - val_presence_of_other_faces_or_toys_loss: 0.1377 - val_blurred_acc: 0.8496 - val_looking_away_acc: 0.7646 - val_ink_marked_creased_acc: 0.8637 - val_unnatural_skin_tone_acc: 0.7115 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8619 - val_varied_background_acc: 0.7965 - val_roll_pitch_yaw_acc: 0.8336 - val_flash_reflection_on_skin_acc: 0.6673 - val_red_eyes_acc: 0.7451 - val_shadows_behind_head_acc: 0.9593 - val_shadows_across_face_acc: 0.6796 - val_dark_tinted_lenses_acc: 0.9805 - val_flash_reflection_on_lenses_acc: 0.8673 - val_frames_too_heavy_acc: 0.9699 - val_frame_covering_eyes_acc: 0.8566 - val_hat_cap_acc: 0.9381 - val_veil_over_face_acc: 0.9115 - val_mouth_open_acc: 0.6637 - val_presence_of_other_faces_or_toys_acc: 0.9823\n",
      "Epoch 2/3\n",
      "5211/5211 [==============================] - 4s 713us/step - loss: 6.6966 - blurred_loss: 0.3868 - looking_away_loss: 0.6475 - ink_marked_creased_loss: 0.1003 - unnatural_skin_tone_loss: 0.1912 - too_dark_light_loss: 0.1883 - washed_out_loss: 0.0084 - pixelation_loss: 0.2347 - hair_across_eyes_loss: 0.2307 - eyes_closed_loss: 0.4680 - varied_background_loss: 0.2278 - roll_pitch_yaw_loss: 0.5600 - flash_reflection_on_skin_loss: 0.3401 - red_eyes_loss: 0.3477 - shadows_behind_head_loss: 0.5354 - shadows_across_face_loss: 0.2989 - dark_tinted_lenses_loss: 0.1824 - flash_reflection_on_lenses_loss: 0.3107 - frames_too_heavy_loss: 0.2159 - frame_covering_eyes_loss: 0.4033 - hat_cap_loss: 0.2299 - veil_over_face_loss: 0.0930 - mouth_open_loss: 0.4739 - presence_of_other_faces_or_toys_loss: 0.0218 - blurred_acc: 0.8601 - looking_away_acc: 0.7323 - ink_marked_creased_acc: 0.9557 - unnatural_skin_tone_acc: 0.9405 - too_dark_light_acc: 0.9449 - washed_out_acc: 0.9990 - pixelation_acc: 0.9294 - hair_across_eyes_acc: 0.9104 - eyes_closed_acc: 0.8415 - varied_background_acc: 0.9156 - roll_pitch_yaw_acc: 0.7601 - flash_reflection_on_skin_acc: 0.8891 - red_eyes_acc: 0.8668 - shadows_behind_head_acc: 0.7906 - shadows_across_face_acc: 0.8935 - dark_tinted_lenses_acc: 0.9334 - flash_reflection_on_lenses_acc: 0.8755 - frames_too_heavy_acc: 0.9374 - frame_covering_eyes_acc: 0.8495 - hat_cap_acc: 0.9127 - veil_over_face_acc: 0.9722 - mouth_open_acc: 0.8029 - presence_of_other_faces_or_toys_acc: 0.9967 - val_loss: 13.6513 - val_blurred_loss: 0.3736 - val_looking_away_loss: 0.7369 - val_ink_marked_creased_loss: 0.1300 - val_unnatural_skin_tone_loss: 1.4085 - val_too_dark_light_loss: 0.5452 - val_washed_out_loss: 0.5864 - val_pixelation_loss: 0.2339 - val_hair_across_eyes_loss: 0.6243 - val_eyes_closed_loss: 0.5636 - val_varied_background_loss: 1.0765 - val_roll_pitch_yaw_loss: 0.8138 - val_flash_reflection_on_skin_loss: 1.2232 - val_red_eyes_loss: 1.0396 - val_shadows_behind_head_loss: 0.1400 - val_shadows_across_face_loss: 1.6046 - val_dark_tinted_lenses_loss: 0.1023 - val_flash_reflection_on_lenses_loss: 0.4080 - val_frames_too_heavy_loss: 0.1348 - val_frame_covering_eyes_loss: 0.5551 - val_hat_cap_loss: 0.1791 - val_veil_over_face_loss: 0.0972 - val_mouth_open_loss: 0.9552 - val_presence_of_other_faces_or_toys_loss: 0.1198 - val_blurred_acc: 0.8496 - val_looking_away_acc: 0.7805 - val_ink_marked_creased_acc: 0.9345 - val_unnatural_skin_tone_acc: 0.7133 - val_too_dark_light_acc: 0.8779 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8602 - val_varied_background_acc: 0.8248 - val_roll_pitch_yaw_acc: 0.8336 - val_flash_reflection_on_skin_acc: 0.6938 - val_red_eyes_acc: 0.7398 - val_shadows_behind_head_acc: 0.9735 - val_shadows_across_face_acc: 0.6814 - val_dark_tinted_lenses_acc: 0.9823 - val_flash_reflection_on_lenses_acc: 0.9044 - val_frames_too_heavy_acc: 0.9575 - val_frame_covering_eyes_acc: 0.8708 - val_hat_cap_acc: 0.9451 - val_veil_over_face_acc: 0.9735 - val_mouth_open_acc: 0.6867 - val_presence_of_other_faces_or_toys_acc: 0.9823\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5211/5211 [==============================] - 4s 718us/step - loss: 6.1733 - blurred_loss: 0.3528 - looking_away_loss: 0.6114 - ink_marked_creased_loss: 0.0923 - unnatural_skin_tone_loss: 0.1797 - too_dark_light_loss: 0.1679 - washed_out_loss: 0.0075 - pixelation_loss: 0.2216 - hair_across_eyes_loss: 0.2038 - eyes_closed_loss: 0.4285 - varied_background_loss: 0.2052 - roll_pitch_yaw_loss: 0.5415 - flash_reflection_on_skin_loss: 0.3189 - red_eyes_loss: 0.3258 - shadows_behind_head_loss: 0.5025 - shadows_across_face_loss: 0.2735 - dark_tinted_lenses_loss: 0.1624 - flash_reflection_on_lenses_loss: 0.2825 - frames_too_heavy_loss: 0.1919 - frame_covering_eyes_loss: 0.3672 - hat_cap_loss: 0.1963 - veil_over_face_loss: 0.0756 - mouth_open_loss: 0.4449 - presence_of_other_faces_or_toys_loss: 0.0196 - blurred_acc: 0.8693 - looking_away_acc: 0.7559 - ink_marked_creased_acc: 0.9591 - unnatural_skin_tone_acc: 0.9392 - too_dark_light_acc: 0.9493 - washed_out_acc: 0.9990 - pixelation_acc: 0.9300 - hair_across_eyes_acc: 0.9219 - eyes_closed_acc: 0.8549 - varied_background_acc: 0.9257 - roll_pitch_yaw_acc: 0.7680 - flash_reflection_on_skin_acc: 0.8941 - red_eyes_acc: 0.8768 - shadows_behind_head_acc: 0.8045 - shadows_across_face_acc: 0.9062 - dark_tinted_lenses_acc: 0.9440 - flash_reflection_on_lenses_acc: 0.8885 - frames_too_heavy_acc: 0.9426 - frame_covering_eyes_acc: 0.8611 - hat_cap_acc: 0.9284 - veil_over_face_acc: 0.9802 - mouth_open_acc: 0.8127 - presence_of_other_faces_or_toys_acc: 0.9967 - val_loss: 13.3571 - val_blurred_loss: 0.3343 - val_looking_away_loss: 0.7016 - val_ink_marked_creased_loss: 0.1899 - val_unnatural_skin_tone_loss: 1.4044 - val_too_dark_light_loss: 0.4585 - val_washed_out_loss: 0.5434 - val_pixelation_loss: 0.2303 - val_hair_across_eyes_loss: 0.7155 - val_eyes_closed_loss: 0.5013 - val_varied_background_loss: 1.0962 - val_roll_pitch_yaw_loss: 0.8862 - val_flash_reflection_on_skin_loss: 1.2670 - val_red_eyes_loss: 0.8870 - val_shadows_behind_head_loss: 0.1309 - val_shadows_across_face_loss: 1.3246 - val_dark_tinted_lenses_loss: 0.1554 - val_flash_reflection_on_lenses_loss: 0.4042 - val_frames_too_heavy_loss: 0.1831 - val_frame_covering_eyes_loss: 0.5321 - val_hat_cap_loss: 0.1530 - val_veil_over_face_loss: 0.0766 - val_mouth_open_loss: 1.0605 - val_presence_of_other_faces_or_toys_loss: 0.1214 - val_blurred_acc: 0.8566 - val_looking_away_acc: 0.7858 - val_ink_marked_creased_acc: 0.8619 - val_unnatural_skin_tone_acc: 0.7133 - val_too_dark_light_acc: 0.8796 - val_washed_out_acc: 0.9398 - val_pixelation_acc: 0.9487 - val_hair_across_eyes_acc: 0.9150 - val_eyes_closed_acc: 0.8619 - val_varied_background_acc: 0.8265 - val_roll_pitch_yaw_acc: 0.8336 - val_flash_reflection_on_skin_acc: 0.6938 - val_red_eyes_acc: 0.7522 - val_shadows_behind_head_acc: 0.9823 - val_shadows_across_face_acc: 0.6743 - val_dark_tinted_lenses_acc: 0.9699 - val_flash_reflection_on_lenses_acc: 0.9009 - val_frames_too_heavy_acc: 0.9469 - val_frame_covering_eyes_acc: 0.8761 - val_hat_cap_acc: 0.9469 - val_veil_over_face_acc: 0.9788 - val_mouth_open_acc: 0.6035 - val_presence_of_other_faces_or_toys_acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blurred</th>\n",
       "      <td>0.511257</td>\n",
       "      <td>0.359057</td>\n",
       "      <td>82.920745</td>\n",
       "      <td>84.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking_away</th>\n",
       "      <td>0.794689</td>\n",
       "      <td>0.730582</td>\n",
       "      <td>68.221071</td>\n",
       "      <td>76.460177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ink_marked_creased</th>\n",
       "      <td>0.147863</td>\n",
       "      <td>0.205618</td>\n",
       "      <td>94.492420</td>\n",
       "      <td>86.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unnatural_skin_tone</th>\n",
       "      <td>0.290424</td>\n",
       "      <td>1.324145</td>\n",
       "      <td>92.112838</td>\n",
       "      <td>71.150442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too_dark_light</th>\n",
       "      <td>0.253213</td>\n",
       "      <td>0.510488</td>\n",
       "      <td>93.897524</td>\n",
       "      <td>87.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washed_out</th>\n",
       "      <td>0.045857</td>\n",
       "      <td>0.664190</td>\n",
       "      <td>98.445596</td>\n",
       "      <td>93.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixelation</th>\n",
       "      <td>0.308188</td>\n",
       "      <td>0.251719</td>\n",
       "      <td>91.326041</td>\n",
       "      <td>94.867257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair_across_eyes</th>\n",
       "      <td>0.304744</td>\n",
       "      <td>0.667968</td>\n",
       "      <td>88.831318</td>\n",
       "      <td>91.504425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes_closed</th>\n",
       "      <td>0.573182</td>\n",
       "      <td>0.523374</td>\n",
       "      <td>80.944157</td>\n",
       "      <td>86.194690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varied_background</th>\n",
       "      <td>0.357393</td>\n",
       "      <td>1.268238</td>\n",
       "      <td>86.048743</td>\n",
       "      <td>79.646018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll_pitch_yaw</th>\n",
       "      <td>0.642837</td>\n",
       "      <td>0.879711</td>\n",
       "      <td>71.022836</td>\n",
       "      <td>83.362832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_skin</th>\n",
       "      <td>0.457598</td>\n",
       "      <td>1.014075</td>\n",
       "      <td>83.861063</td>\n",
       "      <td>66.725664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_eyes</th>\n",
       "      <td>0.413685</td>\n",
       "      <td>0.847737</td>\n",
       "      <td>84.148916</td>\n",
       "      <td>74.513274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_behind_head</th>\n",
       "      <td>0.666800</td>\n",
       "      <td>0.181937</td>\n",
       "      <td>75.398196</td>\n",
       "      <td>95.929204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadows_across_face</th>\n",
       "      <td>0.383051</td>\n",
       "      <td>1.623086</td>\n",
       "      <td>85.876031</td>\n",
       "      <td>67.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_tinted_lenses</th>\n",
       "      <td>0.256542</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>90.731146</td>\n",
       "      <td>98.053097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_reflection_on_lenses</th>\n",
       "      <td>0.402083</td>\n",
       "      <td>0.447103</td>\n",
       "      <td>83.554020</td>\n",
       "      <td>86.725664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frames_too_heavy</th>\n",
       "      <td>0.336755</td>\n",
       "      <td>0.105173</td>\n",
       "      <td>90.078680</td>\n",
       "      <td>96.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_covering_eyes</th>\n",
       "      <td>0.510414</td>\n",
       "      <td>0.536543</td>\n",
       "      <td>82.402610</td>\n",
       "      <td>85.663717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hat_cap</th>\n",
       "      <td>0.339429</td>\n",
       "      <td>0.181778</td>\n",
       "      <td>87.238534</td>\n",
       "      <td>93.805310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil_over_face</th>\n",
       "      <td>0.221526</td>\n",
       "      <td>0.173635</td>\n",
       "      <td>93.206678</td>\n",
       "      <td>91.150442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_open</th>\n",
       "      <td>0.589713</td>\n",
       "      <td>1.041585</td>\n",
       "      <td>76.549607</td>\n",
       "      <td>66.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presence_of_other_faces_or_toys</th>\n",
       "      <td>0.038856</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>99.481865</td>\n",
       "      <td>98.230088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loss_train  loss_val  acc_train    acc_val\n",
       "blurred                            0.511257  0.359057  82.920745  84.955752\n",
       "looking_away                       0.794689  0.730582  68.221071  76.460177\n",
       "ink_marked_creased                 0.147863  0.205618  94.492420  86.371681\n",
       "unnatural_skin_tone                0.290424  1.324145  92.112838  71.150442\n",
       "too_dark_light                     0.253213  0.510488  93.897524  87.964602\n",
       "washed_out                         0.045857  0.664190  98.445596  93.982301\n",
       "pixelation                         0.308188  0.251719  91.326041  94.867257\n",
       "hair_across_eyes                   0.304744  0.667968  88.831318  91.504425\n",
       "eyes_closed                        0.573182  0.523374  80.944157  86.194690\n",
       "varied_background                  0.357393  1.268238  86.048743  79.646018\n",
       "roll_pitch_yaw                     0.642837  0.879711  71.022836  83.362832\n",
       "flash_reflection_on_skin           0.457598  1.014075  83.861063  66.725664\n",
       "red_eyes                           0.413685  0.847737  84.148916  74.513274\n",
       "shadows_behind_head                0.666800  0.181937  75.398196  95.929204\n",
       "shadows_across_face                0.383051  1.623086  85.876031  67.964602\n",
       "dark_tinted_lenses                 0.256542  0.122984  90.731146  98.053097\n",
       "flash_reflection_on_lenses         0.402083  0.447103  83.554020  86.725664\n",
       "frames_too_heavy                   0.336755  0.105173  90.078680  96.991150\n",
       "frame_covering_eyes                0.510414  0.536543  82.402610  85.663717\n",
       "hat_cap                            0.339429  0.181778  87.238534  93.805310\n",
       "veil_over_face                     0.221526  0.173635  93.206678  91.150442\n",
       "mouth_open                         0.589713  1.041585  76.549607  66.371681\n",
       "presence_of_other_faces_or_toys    0.038856  0.137718  99.481865  98.230088"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = model.fit(train_features, \n",
    "                 np.hsplit(y_train, range(1, y_train.shape[1])), \n",
    "                 batch_size=32, \n",
    "                 epochs=3, \n",
    "                 validation_data=(val_features, np.hsplit(y_val, range(1, y_val.shape[1]))))\n",
    "\n",
    "save_history(hist.history, 'images/history.pdf')\n",
    "history_to_dataframe(hist.history, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = np.hsplit(y_val, range(1, y_val.shape[1]))\n",
    "y_preds = model.predict(val_features)\n",
    "\n",
    "save_heatmaps(y_trues, y_preds, output_file='images/heatmaps.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
